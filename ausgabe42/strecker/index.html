
<!DOCTYPE HTML>

<html lang="de">

<head>
	<meta charset="utf-8">
	<title>Dataset Retrieval: Informationsverhalten von Datensuchenden und das Ökosystem von Data-Retrieval-Systemen - LIBREAS. Library Ideas</title>
	<meta name="author" content="LIBREAS. Library Ideas">


<!-- RDFa DC -->

 <!-- RDFa Metadata (in DublinCore) -->
    
    <meta property="dc:title" content="Dataset Retrieval: Informationsverhalten von Datensuchenden und das Ökosystem von Data-Retrieval-Systemen" />
    
    
    
    <meta property="dc:creator" content="Dorothea Strecker" />
    
    
    
    <meta property="dc:date" content="2022" />
    
    <meta property="dc:format" content="text/html" />
    <meta property="dc:language" content="de" />
    <meta property="dc:identifier" content="https://libreas.eu/ausgabe42/strecker/index.html" />
    
    <meta property="dc:rights" prefix="cc: http://creativecommons.org/ns#" rel="cc:license" href="https://creativecommons.org/licenses/by/4.0/" content="CC-BY 4.0" />
	
    <meta property="dc:source" content="LIBREAS. Library Ideas" />
    <meta property="dc:subject" content="Library and Information Science" />
    <meta property="dc:type" content="website" />
    <meta property="dc:description" content="Verschiedene Stakeholder fordern eine bessere Verfügbarkeit von Forschungsdaten. Der Erfolg dieser Initiativen hängt wesentlich von einer guten Auffindbarkeit der publizierten Datensätze ab, weshalb Dataset Retrieval an Bedeutung gewinnt. Dataset Retrieval ist eine Sonderform von Information Retrieval, die sich mit dem Auffinden von Datensätzen befasst. Dieser Beitrag fasst aktuelle Forschungsergebnisse über das Informationsverhalten von Datensuchenden zusammen. Anschließend werden beispielhaft zwei Suchdienste verschiedener Ausrichtung vorgestellt und verglichen. Um darzulegen, wie diese Dienste ineinandergreifen, werden inhaltliche Überschneidungen von Datenbeständen genutzt, um den Metadatenaustausch zu analysieren."/>
    <meta property="dc:source" resource="urn:ISSN:1860-7950" /> 

<!-- Google Scholar -->

	<meta name="citation_journal_title" content="LIBREAS. Library Ideas" />
	<meta name="citation_issue" content="42" />
	<meta name="citation_issn" content="1860-7950" />
	
    <meta name="citation_publication_date" content="2022" />
    


  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

	<link href="/atom.xml" rel="alternate" title="LIBREAS. Library Ideas" type="application/atom+xml">
	
	<link rel="canonical" href="https://libreas.eu/ausgabe42/strecker/">
	<link href="/favicon.png" rel="shortcut icon">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">


    <!--   
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="favicon.png"> -->
  
	
</head>




  <body class="theme-base-wes">

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <a href="/">LIBREAS. Library Ideas</a>
  </div>

  <nav class="sidebar-nav">

    	<a class="sidebar-nav-item" href="/ausgabe43/">Aktuelle Ausgabe</a>
	<a class="sidebar-nav-item" href="/archiv.htm">Archiv</a>
	<a class="sidebar-nav-item" href="http://edoc.hu-berlin.de/browsing/libreas/">edoc pdf-Archiv</a>
	<a class="sidebar-nav-item" href="/autorinnen">Autor*innen</a>
	<a class="sidebar-nav-item" href="http://libreas.wordpress.com/category/libreas-call-for-papers/">Call for Papers</a>
	<a class="sidebar-nav-item" href="/authorguides">Author guidelines</a>
	<a class="sidebar-nav-item" href="http://libreas.wordpress.com/">Blog</a>
	<a class="sidebar-nav-item" href="http://libreas.tumblr.com/">Tumblr</a>
    <a class="sidebar-nav-item" href="/dldl.html">DLDL</a>
	<a class="sidebar-nav-item" href="https://web.archive.org/web/20171112100417/http://www.ib.hu-berlin.de/~libreas/libreas_neu/podcasts/">Podcasts</a>
	<a class="sidebar-nav-item" href="http://libreas-verein.eu">Verein</a>
	<a class="sidebar-nav-item" href="/about">Impressum</a>

  </nav>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <!-- <div class="wrap">
       <div class="masthead">
        <div class="container">
          <h1 class="masthead-title">
            <a href="/" title="Home">LIBREAS. Library Ideas</a>
            <small><br></small>
          </h1>
        </div>
      </div> -->


      <div class="container content">
      <!-- GitHub et al icon -->
      <div align="right" class="icons">
        <a href="mailto:redaktion@libreas.eu"><i class="fa fa-envelope"></i></a>
        <a href="https://github.com/libreas"><i class="fa fa-github-square"></i></a>
        <a href="https://www.instagram.com/libreas.libraryideas/"><i class="fa fa-instagram"></i></a>
        <a href="https://twitter.com/libreas"><i class="fa fa-twitter"></i></a>
        <a href="https://edoc.hu-berlin.de/feed/atom_1.0/18452/149"><i class="fa fa-rss"></i></a>
</div>
        
<article class="page" itemscope itemtype="http://schema.org/ScholarlyArticle">

<div align="right">

<strong> > > > <a href="/ausgabe42/inhalt/">LIBREAS. Library Ideas # 42</a></strong> <br><br></div>




    
        
    
    <div align="right">
    <p><small><a itemprop="sameAs" href="https://via.hypothes.is/https://libreas.eu/ausgabe42/strecker/">Annotate via hypothes.is</a></small></p>
        <small><a itemprop="sameAs" href="https://doi.org/10.18452/25691">Download PDF</a></small>
        </div>
    
    
    <div align="right">
        <small><a itemprop="sameAs" href="https://doi.org/10.18452/25691">doi:10.18452/25691</a> (edoc HU Berlin)</small>
        </div>
        

        
        <h1 itemprop="name" class="title">Dataset Retrieval: Informationsverhalten von Datensuchenden und das Ökosystem von Data-Retrieval-Systemen</h1>
        
        

        <div class="titelei">
        
        <i itemprop="author">Dorothea Strecker</i>
        
    </div>

<!-- 

        
        <div class="titelei">
            
              
              
            <i itemprop="author">Dorothea Strecker</i> 
            
            
            
        </div>
 -->



        

        <p><small itemprop="description">Verschiedene Stakeholder fordern eine bessere Verfügbarkeit von Forschungsdaten. Der Erfolg dieser Initiativen hängt wesentlich von einer guten Auffindbarkeit der publizierten Datensätze ab, weshalb Dataset Retrieval an Bedeutung gewinnt. Dataset Retrieval ist eine Sonderform von Information Retrieval, die sich mit dem Auffinden von Datensätzen befasst. Dieser Beitrag fasst aktuelle Forschungsergebnisse über das Informationsverhalten von Datensuchenden zusammen. Anschließend werden beispielhaft zwei Suchdienste verschiedener Ausrichtung vorgestellt und verglichen. Um darzulegen, wie diese Dienste ineinandergreifen, werden inhaltliche Überschneidungen von Datenbeständen genutzt, um den Metadatenaustausch zu analysieren.</small></p>

        

        

        <br>

        <p><small itemprop="description">Various stakeholders are calling for better availability of research data. The success of these initiatives depends largely on good discoverability of published datasets, which is why Dataset Retrieval is gaining in importance. Dataset Retrieval is a special form of Information Retrieval that is concerned with finding datasets. This paper summarizes recent research on the information behavior of data users. Subsequently, two search services with different objectives are presented and compared. In order to show how these services interconnect, overlaps in content are used to analyze metadata exchange between them.</small></p>

        



        
        <p>
          <small>
            <br>
            Zitiervorschlag
            <br>
            
            
            Dorothea Strecker,
            
            
             
            "Dataset Retrieval: Informationsverhalten von Datensuchenden und das Ökosystem von Data-Retrieval-Systemen".
            
            <i itemprop="provider">LIBREAS. Library Ideas</i>, 42 (<span itemprop="datePublished">2022</span>). <a itemprop="url" href="https://libreas.eu/ausgabe42/strecker/">https://libreas.eu/ausgabe42/strecker/</a>
        </small>
        <hr>
    </p>
   
    





    <div class="entry-content" itemprop="articleBody"><nav id="TOC" role="doc-toc">
<ul>
<li><a href="#einleitung" id="toc-einleitung">Einleitung</a></li>
<li><a href="#literaturübersicht"
id="toc-literaturübersicht">Literaturübersicht</a></li>
<li><a href="#methode" id="toc-methode">Methode</a></li>
<li><a href="#ergebnisse" id="toc-ergebnisse">Ergebnisse</a></li>
<li><a href="#diskussion" id="toc-diskussion">Diskussion</a></li>
<li><a href="#fazit" id="toc-fazit">Fazit</a></li>
<li><a href="#anhang-a" id="toc-anhang-a">Anhang A</a></li>
<li><a href="#literaturverzeichnis"
id="toc-literaturverzeichnis">Literaturverzeichnis</a></li>
</ul>
</nav>
<h3 id="einleitung">Einleitung</h3>
<p>Um die Nachvollziehbarkeit und Nachnutzbarkeit von
Forschungsergebnissen zu fördern, fordern verschiedene Stakeholder eine
bessere Verfügbarkeit von Forschungsdaten. Der Erfolg dieser Initiativen
hängt allerdings wesentlich von einer guten Auffindbarkeit der
publizierten Datensätze ab, denn der Kreis von der Publikation bis zur
Nachnutzung bestehender Forschungsdaten lässt sich nur schließen, wenn
für die jeweilige Fragestellung passende Daten gefunden werden
können.</p>
<p>Verschiedene Aspekte von Information Retrieval werden schon lange
beforscht, inzwischen hat sich ein eigenständiges Forschungsfeld
etabliert (Luk 2022). Im Zuge der wachsenden Anzahl publizierter
Forschungsdaten kommen auch Retrieval-Systeme auf, die sich auf das
Auffinden von Forschungsdaten spezialisiert haben. Diese Entwicklung
bringt neue Fragestellungen und Herausforderungen mit sich.</p>
<p>Beispielsweise müssen Informationsbedürfnisse und -verhalten von
Datensuchenden analysiert werden, um bedarfsgerechte Angebote entwickeln
zu können. Außerdem muss sich ein stabiles Ökosystem von Suchdiensten
entwickeln, die variierende Bestände durchsuchbar machen, wie es
beispielsweise im Bibliotheksbereich schon lange existiert.</p>
<h4 id="fragestellungen">Fragestellungen</h4>
<p>In diesem Beitrag soll darum dargestellt werden, was aktuell über das
Informationsverhalten von Datensuchenden bekannt ist. Anschließend
werden beispielhaft zwei Suchdienste – PANGAEA und Google Dataset Search
– mit besonderem Fokus auf Unterschiede in ihrer Datengrundlage und
Funktionsweise vorgestellt. Um zu zeigen, wie diese Dienste
ineinandergreifen, werden inhaltliche Überschneidungen von
Datenbeständen genutzt, um den Metadatenaustausch zu analysieren.</p>
<h3 id="literaturübersicht">Literaturübersicht</h3>
<h4 id="information-retrieval-und-dataset-retrieval">Information
Retrieval und Dataset Retrieval</h4>
<p>Allgemein bezeichnet Information Retrieval (IR) den Prozess, bei dem
gezielt nach Informationsobjekten in einer Sammlung gesucht wird, die
ein bestimmtes Informationsbedürfnis abdecken (Meadow et al. 2007).
Systeme, die IR ermöglichen, repräsentieren und organisieren
Informationen auf unterschiedliche Weise, um sie durchsuchbar zu machen,
und bieten verschiedene Einstiege für die Suche an. Die Ursprünge von IR
sind eng mit der Entwicklung des Bibliothekswesens verknüpft (Sanderson
und Croft 2012). Im Laufe der Zeit haben sich IR-Systeme wesentlich
weiterentwickelt, und IR hat sich als eigenständige Forschungsdisziplin
etabliert (Luk 2022).</p>
<p>Dataset Retrieval (DR) kann als Sonderform von IR betrachtet werden,
die sich auf das Auffinden von Informationsobjekten eines besonderen
Typs (Datensätze) spezialisiert (Chen et al. 2019; Kunze und Auer 2013).
DR ist ein vergleichsweise neues Forschungsfeld, das sich in der
Anfangszeit vorwiegend mit technischen Herausforderungen beschäftigt
hat; soziale Aspekte wie Informationsbedürfnisse und -verhalten wurden
erst in den letzten Jahren systematisch beforscht (Gregory, Cousijn, et
al. 2020). Diese Aspekte sind jedoch wichtig, um das
Informationsverhalten von Datensuchenden zu verstehen und daraus
Anforderungen an DR-Systeme abzuleiten.</p>
<h4 id="funktionsweise-von-dr-systemen">Funktionsweise von
DR-Systemen</h4>
<p>Grundsätzlich funktionieren DR-Systeme wie andere IR-Systeme: Eine
Anfrage durch Nutzende erfolgt in den Phasen <em>querying</em> (Stellen
der Anfrage durch den*die Nutzer*in), <em>query handling</em>
(Bearbeitung der Anfrage durch den Suchdienst), <em>data handling</em>
(Identifizieren von Treffern durch den Suchdienst) und <em>results
presentation</em> (Anzeigen der Treffer durch den Suchdienst) (Chapman
et al. 2020). Das DR-System erstellt im Voraus einen Index der
durchsuchbaren Dokumente und beinhaltet Komponenten, die Anfragen mit
dem Index abgleichen und Trefferlisten erstellen (Chen et al. 2019). Der
Index kann auf verschiedene Weise erzeugt werden, beispielsweise durch
das gezielte Harvesten von Metadaten über die Schnittstellen
ausgewählter Dienste oder durch Crawls, die regelmäßig eine große Zahl
von Repositorien ansteuern (Chapman et al. 2020). DR basiert aktuell
überwiegend auf strukturierten Metadaten, die Repositorien bereitstellen
(Chapman et al. 2020; Devaraju und Berkovsky 2018). Ansätze zur
Anreicherung des Indexes wie die Volltextindexierung von Publikationen,
die auf den durchsuchbaren Datensätzen aufbauen, sind bisher noch wenig
verbreitet (Khalsa, Cotroneo, und Wu 2018).</p>
<p>Aktuell sind die Suchfunktionalitäten von DR-Systemen vorwiegend auf
Keywordsuche und facettierte Navigation beschränkt (Devaraju und
Berkovsky 2018). Um den Ansprüchen von Nutzenden gerecht zu werden,
sollten Repositorien möglichst mehrere Sucheinstiege anbieten,
beispielsweise neben einem einfachen Suchschlitz auch eine erweiterte
Suche, die Suche über eine Karte oder Browsing nach Facetten (Wu et al.
2019) – was viele Repositorien bereits umgesetzt haben (Khalsa,
Cotroneo, und Wu 2018).</p>
<h4 id="evaluation-von-dr-systemen">Evaluation von DR-Systemen</h4>
<p>Ein ungelöstes Problem ist die Evaluation von DR-Systemen. In einer
Umfrage von 2018 unter 98 Repositorienbetreiber*innen gab nur etwa ein
Drittel der Befragten an, das DR-System in der Vergangenheit evaluiert
zu haben, und nur etwa die Hälfte war sich sicher, dass die meisten
Anfragen durch das System für Nutzer*innen zufriedenstellend beantwortet
werden (Khalsa, Cotroneo, und Wu 2018). Ein Grund dafür könnte sein,
dass verbreitete Metriken und Benchmarks für die Evaluation von
IR-Systemen häufig auf Textdokumente ausgelegt sind und nicht immer
direkt auf Datensätze übertragbar sind (Chapman et al. 2020).</p>
<p>Trotz dieser Herausforderungen gibt es einige Publikationen, die
Aspekte von DR-Systemen evaluieren. So zeigte sich beispielsweise, dass
die Relevanzbewertung von Treffern noch besser an spezifische
Besonderheiten von Datensätzen angepasst werden könnte (Dede Şener,
Ogul, und Basak 2022). Auch verschiedene Ansätze für
Recommender-Services, die ähnliche Datensätze aufzeigen, wurden erprobt
(Wang, Huang, und Harmelen 2020).</p>
<p>Es gibt erste Hinweise darauf, dass integrierte Retrieval-Systeme,
die sowohl Daten- und Textpublikationen auffindbar machen,
unterschiedlich gut mit diesen Dokumenttypen umgehen. In einem solchen
integrierten System waren einige populäre Datensätze sehr gut, viele
andere dagegen weniger gut auffindbar (Roy, Carevic, und Mayr 2022). Die
Auffindbarkeit bei Textpublikationen war im Vergleich gleichmäßiger
verteilt, außerdem führte die Suche nach Textpublikationen wesentlich
häufiger zu direkten Interaktionen mit Inhalten.</p>
<h4
id="informationsverhalten-im-kontext-von-forschungsdaten">Informationsverhalten
im Kontext von Forschungsdaten</h4>
<p>Borst und Limani (2020) stellen <em>data search</em> als dreiteiliges
Konzept dar, das die Aspekte <em>discovery</em> (Suche nach Datensätzen
in einem Retrievalsystem), <em>exploration</em> (Inhalt und Struktur
eines Datensatzes mithilfe der Metadaten erkunden) und <em>analysis</em>
(Teile eines Datensatzes gemäß einer Fragestellung und
datensatzspezifischer Eigenschaften auswählen) umfasst. In diesem
Beitrag wird vorwiegend der Aspekt <em>discovery</em> behandelt.<br />
Forschende suchen Daten für diverse Nachnutzungsszenarien (Gregory et
al. 2019). Diese lassen sich grob in <em>background</em>-Nutzung (wie
etwa die Kalibrierung von Messinstrumenten oder den Einsatz von Daten in
der Lehre) und <em>foreground</em>-Nutzung (wie etwa das Beantworten
eigener, neuer Fragestellungen anhand nachgenutzter Daten) unterteilen
(Gregory, Cousijn, et al. 2020).</p>
<p>Aktuell basieren DR-Ansätze überwiegend auf Erfahrungen mit der Suche
nach Textdokumenten (Borst und Limani 2020). Die Suche nach Daten
unterscheidet sich jedoch in einigen zentralen Aspekten von der Suche
nach Textpublikationen. So sind Daten im Vergleich komplexere Objekte,
da sie auch Begleitmaterial wie Codebücher beinhalten können (Carevic,
Roy, und Mayr 2020). Zudem sind die Anforderungen an DR deutlich
vielfältiger: DR-Systeme werden je nach Informationsbedürfnis auch mit
Aspekten wie Provenienz, Qualität, Granularität und Interoperabilität
von Daten konfrontiert (Chapman et al. 2020). Darum werden Metadaten bei
DR wichtiger eingeschätzt, da Forschende über Metadaten den Kontext der
Daten verstehen und die Nutzbarkeit bewerten können (Kern und Mathiak
2015).</p>
<h5 id="suchstrategien">Suchstrategien</h5>
<p>In einer Umfrage von 2020 unter 1.677 Forschenden berichtete die
Mehrzahl der Befragten, dass sie die Suche nach Daten herausfordernd
oder sogar schwierig finden; ein Drittel gab als Grund dafür
unzureichende Suchdienste an (Gregory, Groth, et al. 2020). Forschende
nutzen für das Auffinden von Datensätzen verschiedene Quellen und
Strategien. Häufig genutzt werden beispielsweise persönliche Kontakte,
Verweise in Textpublikationen oder Websuchmaschinen (Friedrich 2020;
Gregory, Groth, et al. 2020; Krämer et al. 2021). Die Nutzung
spezialisierter Dienste wie Forschungsdatenrepositorien oder
Suchmaschinen für Forschungsdaten ist demgegenüber weniger verbreitet
(Gregory, Groth, et al. 2020). Insbesondere zu Beginn eines
Suchprozesses nutzen Forschende häufig Websuchmaschinen, sowohl um
Daten- oder Textpublikationen als auch um spezialisierte Angebote für
die Datensuche zu finden (Krämer et al. 2021). Allgemeine
Berufserfahrung scheint einen positiven Einfluss auf die Diversität der
Quellen zu haben, die Forschende für DR nutzen (Friedrich 2020). Eine
erste Metaanalyse zeigt, dass sich die Informationsbedürfnisse und
Herausforderungen von Forschenden und Forschungsdatenexpert*innen wie
Data Librarians, ähneln (Sun et al. 2022). Allerdings nutzen sie
unterschiedliche Strategien, um geeignete Daten zu finden – so nutzen
Data Librarians weniger häufig Websuchmaschinen.</p>
<p>Wenn Forschende Websuchmaschinen für DR nutzen, ergänzen sie die
Suchanfrage häufig um Begriffe wie <q>data</q> oder <q>dataset</q>, um
ihr Bedürfnis zu präzisieren (Koesten et al. 2017; Krämer et al. 2021).
Websuchmaschinen spielen auch eine wichtige Rolle beim Auffinden
spezialisierter Datensuchdienste. Die Logfiles von Open-Data-Portalen
zeigen beispielsweise, dass die meisten Nutzer*innen über
Websuchmaschinen auf die Seiten der Portale gelangten (Kacprzak et al.
2019; Koesten et al. 2017). Obwohl viele Nutzer*innen die
Open-Data-Portale und ihre Inhalte bereits kannten, was die gehäufte
Nennung dieser Portale in den Anfragen an Websuchmaschinen nahelegt,
zogen sie offenbar die Suchfunktion der Websuchmaschinen den
Open-Data-Portalen vor. Nutzer*innen, die von externen Diensten wie
Websuchmaschinen auf Inhalte von Open-Data-Portalen verwiesen wurden,
brachen ihre Suche allerdings auch schneller erfolglos ab als
Nutzer*innen, die den gesamten Suchprozess im Portal durchführten
(Ibáñez und Simperl 2022).</p>
<p>Im Vergleich zu Suchanfragen an Websuchmaschinen sind Suchanfragen an
spezialisierte Datensuchdienste in der Tendenz kürzer. Suchanfragen an
Open-Data-Portale umfassten im Durchschnitt beispielsweise zwischen 1,63
und 2,52 Wörter (Kacprzak et al. 2017). Forschende scheinen kurze
Suchanfragen bewusst einzusetzen, um lange Trefferlisten zu erstellen,
die sie dann manuell auf Nutzbarkeit überprüfen (Kacprzak et al. 2019;
Koesten et al. 2017). Beim DR über spezialisierte Datensuchdienste
enthalten Suchanfragen außerdem häufiger Ziffern, räumliche oder
zeitliche Einschränkungen in verschiedenen Granularitätsstufen oder die
Nennung spezieller Datentypen oder -formate (Carevic, Roy, und Mayr
2020; Kacprzak et al. 2019). Suchanfragen an Datensuchdienste scheinen
insgesamt ein breiteres Spektrum von Themen abzudecken (Kacprzak et al.
2019). Bei der Suche nach Daten sind sich Suchanfragen, die innerhalb
einer Session gestellt werden, thematisch ähnlicher als bei der Suche
nach Textpublikationen (Carevic, Roy, und Mayr 2020). Interaktionspfade
bei der Suche nach Daten- und Textpublikationen ähneln sich generell,
allerdings werden Anfragen bei der Suche nach Textpublikationen häufiger
umformuliert und neu gestellt (Carevic, Roy, und Mayr 2020).</p>
<p>Unklar ist noch, in welchem Umfang <em>known-item search</em>
auftritt – die Suche nach einem bestimmten, bereits bekannten Datensatz.
Dass beim DR explorative Ansätze verfolgt werden, zeigt sich
beispielsweise daran, dass Suchende durch kurze Suchanfragen bewusst
lange Trefferlisten erzeugen (Kacprzak et al. 2017, 2019). Jedoch gibt
es keine Einigkeit über die Verbreitung von <em>known-item search</em>:
Analysen zeigen, dass Anfragen an spezialisierte Datensuchdienste selten
angepasst und verändert neu gestellt werden (Koesten et al. 2017;
Carevic, Roy, und Mayr 2020). In diesem Bereich ist mehr Forschung
erforderlich, um <em>known-item search</em> in DR-Systemen besser
unterstützen zu können.</p>
<p>Die hier beschriebenen Studien des Informationsverhaltens in Bezug
auf DR legen nahe, dass es bisher kaum einheitliche und bewährte
Strategien für die Suche nach Datensätzen gibt (Krämer et al. 2021).</p>
<h4 id="arten-von-dr-systemen">Arten von DR-Systemen</h4>
<p>Grundlegend gibt es verschiedene Arten von DR-Systemen. Sie bilden
ein komplexes Ökosystem, in dem jeder Dienst abhängig von der Mission
und Nutzer*innengruppe verschiedene Bedürfnisse abdeckt. Beispielsweise
können DR-Systeme in zentrale und dezentrale Angebote unterteilt werden
(Chapman et al. 2020). Sie divergieren darin, ob ein zentraler Bestand
durchsuchbar gemacht wird oder ob Inhalte mehrerer Quellen
zusammengeführt werden (Borst und Limani 2020). Suchdienste
unterscheiden sich außerdem in ihrem disziplinären Fokus:
Disziplinübergreifende Angebote machen Bestände mehrerer Disziplinen
durchsuchbar, während sich disziplinspezifische DR-Systeme auf Daten
einer Disziplin konzentrieren.<br />
Im Folgenden werden beispielhaft zwei DR-Systeme vorgestellt und
verglichen, die verschiedenen Ansätzen folgen. Google Dataset Search,
ein sehr umfassender dezentraler und disziplinübergreigender Dienst,
wird PANGAEA, einem zentralen und disziplinspezifischen Dienst
gegenübergestellt.</p>
<h5
id="dezentral-und-disziplinübergreifend-google-dataset-search">Dezentral
und disziplinübergreifend: Google Dataset Search</h5>
<p>2018 wurde Google Dataset Search in der Beta-Version veröffentlicht.
Der Dienst nahm 2020 offiziell den Betrieb auf (Noy und Benjelloun
2020).</p>
<p><strong>Datenquellen:</strong> Der Index von Google Dataset Search
basiert zwar auf Crawls, im Gegensatz zur Google Websuchmaschine aber
zugleich auf strukturierten Metadaten. Datenlieferanten zeichnen
Metadaten nach bestimmten Standards (schema.org und DCAT) aus und
stellen diese strukturierten Metadaten über die landing pages
individueller Datensätze zur Verfügung. Ein Crawler sammelt diese
Metadaten, die anschließend verarbeitet und indexiert werden. Anfragen
von Nutzenden werden mit dem Index abgeglichen und Ergebnisse nach
Relevanz sortiert angezeigt. Die Relevanzbewertung basiert auf demselben
Ansatz wie die Google Websuchmaschine, bezieht jedoch auch Aspekte von
Metadatenqualität ein (Brickley, Burgess, und Noy 2019).<br />
Die Größenverteilung der Datenquellen in Google Dataset Search ist stark
verzerrt: Die 20 größten Datenlieferanten machen 78 % des gesamten
Bestands aus (Benjelloun, Chen, und Noy 2020). Welche Inhalte der Google
Dataset Search Index im Detail umfasst, ist unbekannt. Google Dataset
Search indexiert auch Aggregatoren von Metadaten, beispielsweise
DataCite. Das führt dazu, dass die Registrierung von DOIs neben anderen
Vorteilen auch als Strategie empfohlen wird, um Datensätze über Google
Dataset Search auffindbar zu machen (Masson et al. 2021).</p>
<p><strong>Metadaten:</strong> Da der Dienst disziplinübergreifend
konzipiert ist, ist das verwendete Metadatenschema sehr generisch.
Außerdem gibt es nur zwei Pflichtfelder: Titel und Beschreibung. Daraus
ergeben sich Probleme in Bezug auf die Metadatenqualität, insbesondere
die Vollständigkeit. So sind beispielsweise Lizenzinformationen nur für
34 % der Datensätze verfügbar (Benjelloun, Chen, und Noy 2020).</p>
<p><strong>Sucheinstiege:</strong> Der Sucheinstieg bei Google Dataset
Search ist auf eine einfache Keywordsuche beschränkt, auch die
Präsentation der Ergebnisse ist einfach gehalten. Eine niedrigschwellige
Anwendung muss jedoch kein Nachteil sein, sondern könnte die Nachnutzung
von Daten popularisieren und Anreize für das Publizieren von Datensätzen
schaffen (Canino 2019).</p>
<p><strong>Ergebnispräsentation:</strong> Ergebnisse werden in Google
Dataset Search mit den vorhandenen Metadaten dargestellt (siehe
Abbildung 1). Sofern vorhanden, wird die räumliche Abdeckung des
Datensatzes auf einer Karte gezeigt.</p>
<figure>
<img src="img/abb1_GDS_results.png"
alt="Abbildung 1: Ergebnispräsentation für den Datensatz https://doi.org/10.1594/PANGAEA.122942 in Google Dataset Search" />
<figcaption aria-hidden="true">Abbildung 1: Ergebnispräsentation für den
Datensatz <a href="https://doi.org/10.1594/PANGAEA.122942"
class="uri">https://doi.org/10.1594/PANGAEA.122942</a> in Google Dataset
Search</figcaption>
</figure>
<h5 id="zentral-und-disziplinspezifisch-pangaea">Zentral und
disziplinspezifisch: PANGAEA</h5>
<p>PANGAEA nahm 1994 den Betrieb auf. Das disziplinspezifische
Forschungsdatenrepositorium hat sich auf das Publizieren
georeferenzierter Datensätze aus Bereichen der Erdsystemwissenschaft
spezialisiert (Diepenbroek et al. 2002).</p>
<p><strong>Datenquellen:</strong> Der Suchdienst umfasst die in PANGAEA
publizierten Datensätze.<a href="#fn1" class="footnote-ref" id="fnref1"
role="doc-noteref"><sup>1</sup></a></p>
<p><strong>Metadaten:</strong> Metadaten in PANGAEA sind an die
spezifischen Besonderheiten der publizierten Datensätze angepasst. So
bietet das Format, das zur Beschreibung von Datensätzen genutzt wird,
die Möglichkeit, detaillierte Informationen zu dem dokumentierten
Ereignis, Expeditionen und den Erhebungsmethoden anzugeben (Diepenbroek
et al. 2017). Umfassende Kurations- und Qualitätssicherungsprozesse
stellen die Nützlichkeit der Metadaten sicher.<br />
PANGAEA macht Metadaten offen (unter einer CC0-Lizenz) über
Schnittstellen<a href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a> zugänglich. Der Dienst legt Wert auf
die Interoperabilität der Metadaten und liefert sie in entsprechenden
Formaten an verschiedene Aggregatoren aus, beispielsweise GBIF oder
OpenAIRE. Metadaten werden außerdem nach schema.org ausgezeichnet über
die landing pages bereitgestellt. Diese Aktivitäten führen dazu, dass
die publizierten Datensätze auch in anderen dezentralen DR-Systemen gut
auffindbar sind.</p>
<p><strong>Sucheinstiege:</strong> PANGAEA bietet neben einer einfachen
Keywordsuche auch Browsing nach Disziplinen und über eine Karte an. Das
PANGAEA Data Warehouse ermöglicht Datennutzenden außerdem das effiziente
Zusammenstellen von Datensätzen nach selbst definierten Parametern wie
beispielsweise alle Messungen einer bestimmten Größe für eine Region.<a
href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a></p>
<p><strong>Ergebnispräsentation:</strong> PANGAEA stellt den Kontext von
Datensätzen beispielsweise durch Details zur Datenerhebung oder Projekte
und andere Publikationen, die mit dem Datensatz in Zusammenhang stehen
(siehe Abbildung 2), sehr ausführlich dar. Die räumliche Abdeckung des
Datensatzes wird auf einer Karte abgebildet. Außerdem werden
Zitationsempfehlung, Ansichts- und Downloadzahlen sowie eine Übersicht
der im Datensatz enthaltenen Variablen angezeigt.</p>
<figure>
<img src="img/abb2_PANGAEA_results.png"
alt="Abbildung 2: Ergebnispräsentation für den Datensatz https://doi.org/10.1594/PANGAEA.122942 in PANGAEA" />
<figcaption aria-hidden="true">Abbildung 2: Ergebnispräsentation für den
Datensatz <a href="https://doi.org/10.1594/PANGAEA.122942"
class="uri">https://doi.org/10.1594/PANGAEA.122942</a> in
PANGAEA</figcaption>
</figure>
<h3 id="methode">Methode</h3>
<p>Zwischen den hier vorgestellten Diensten gibt es inhaltliche
Überschneidungen bei den Datenbeständen: Durch das Bereitstellen von
Metadaten über die landing pages sorgt PANGAEA dafür, dass Datensätze
auch in Google Dataset Search indexiert sind. Im Folgenden wird
näherungsweise untersucht, wie erfolgreich Metadaten an Google Dataset
Search übergeben werden. Zu diesem Zweck werden Metadatensätze
verglichen, die in beiden Diensten vorliegen.</p>
<h4 id="datenerhebung">Datenerhebung</h4>
<p>Metadaten für Google Dataset Search stammen aus einem Subset der
indexierten Datensätze, das 2020 veröffentlicht wurde (Google Dataset
Search 2020). Das Subset umfasst 17 Metadatenelemente für Datensätze,
für die eine DOI oder ein anderer Identifier vorlag (3.602.027
Datensätze, Stand 16.10.2020). Da PANGAEA DOIs für alle publizierten
Datensätze vergibt, sind diese auch in dem Datensatz enthalten. Zunächst
wurden DOIs identifiziert, die in beiden Datenquellen auftreten (DOIs,
die am 30.10.2022 über die PANGAEA OAI-OMH-Schnittstelle abrufbar waren
sowie DOIs in dem veröffentlichten Subset von Google Dataset Search).
Diese Bedingung trifft auf 364.255 Metadatensätze zu.</p>
<p>Metadaten für 10.000 zufällig ausgewählte PANGAEA-Datensätze wurden
am 01.11.2022 über die OAI-PMH-Schnittstelle im Format <em>PANGAEA
MetaData</em> abgefragt.<a href="#fn4" class="footnote-ref" id="fnref4"
role="doc-noteref"><sup>4</sup></a></p>
<h4 id="analyse">Analyse</h4>
<p>Zunächst wurde die Nutzung der verfügbaren Metadatenelemente im
Subset von Google Dataset Search analysiert.</p>
<p>Anschließend wurde beispielhaft an zwei Metadatenelementen
untersucht, welche Informationen die beiden vorgestellten Suchdienste
für ein zufällig gewähltes Sample von 10.000 Metadatensätzen
vorhalten:</p>
<ul>
<li>Informationen über die Methode, die der Datenerhebung zugrunde liegt
(<em>method</em> in PANGAEA und <em>measurementTechnique</em> in Google
Dataset Search)</li>
<li>Informationen über Fördermittel, die für die Datenerhebung
bereitgestellt wurden (<em>funder</em> in PANGAEA und <em>funder</em> in
Google Dataset Search)</li>
</ul>
<p>Die zwei beschriebenen Metadatenelemente wurden gewählt, da sie für
PANGAEA-Datensätze häufig nicht in der Google Dataset Search vorlagen.
Die Auswahl zielt auf eine Analyse möglicher Probleme beim
Metadatenaustausch ab.</p>
<h3 id="ergebnisse">Ergebnisse</h3>
<h4 id="metadaten-in-google-dataset-search">Metadaten in Google Dataset
Search</h4>
<p>Abbildung 3 zeigt, wie häufig die verfügbaren Metadatenelemente zur
Beschreibung der PANGAEA-Datensätze in Google Dataset Search genutzt
wurden. Tabelle 1 im Anhang beschreibt die Metadatenelemente und listet
ihre Nutzung im Detail auf.</p>
<figure>
<img src="img/abb3_GDS_element_use.png"
alt="Abbildung 3: Nutzung von Metadatenelementen zur Beschreibung von PANGAEA-Datensätzen in einem Subset von Google Dataset Search (Stand 16.10.2020)" />
<figcaption aria-hidden="true">Abbildung 3: Nutzung von
Metadatenelementen zur Beschreibung von PANGAEA-Datensätzen in einem
Subset von Google Dataset Search (Stand 16.10.2020)</figcaption>
</figure>
<p>Fünf der in Abbildung 3 dargestellten Metadatenelemente sind in allen
untersuchten Metadatensätzen vorhanden. Dazu zählen neben den zwei
Pflichtelementen <em>name</em> und <em>description</em> auch
<em>dateModified</em>, <em>doi</em> und <em>url</em>. Fünf weitere
Elemente werden in über 90 % der Metadatensätze genutzt:
<em>distribution</em>, <em>provider</em>, <em>author</em>,
<em>spatialCoverage</em> und <em>isAccessibleForFree</em>. Die Elemente
<em>variablesMeasured</em> und <em>temporalCoverage</em> liegen für die
Mehrzahl der Metadatensätze vor.</p>
<p>Im Vergleich deutlich weniger genutzt werden <em>funder</em> und
<em>sameAs</em>, während drei Metadatenelemente in diesem Bestand nicht
vorkommen (<em>alternateName</em>, <em>identifier</em>,
<em>measurementTechnique</em>). Die mangelnde Nutzung einiger dieser
Elemente kann damit erklärt werden, dass sie nicht auf alle Datensätze
zutreffen – so hat nicht jeder Datensatz alternative Titel, URLs oder
Identifier, die in den Metadaten abgebildet werden können.</p>
<h4 id="vergleich-zwischen-pangaea-und-google-dataset-search">Vergleich
zwischen PANGAEA und Google Dataset Search</h4>
<p>Abbildung 4 zeigt anhand eines zufällig gewählten Samples von 10.000
Datensätzen, die in beiden Datenquellen beschrieben sind, Unterschiede
in der Verfügbarkeit von Informationen zu Förderung (<em>funder</em>)
und Methoden (<em>method</em>).</p>
<figure>
<img src="img/abb4_comparative_element_use.png"
alt="Abbildung 4: Informationen zu Förderern und Methoden in Google Dataset Search und PANGAEA (Sample von 10.000 Metadatensätzen)" />
<figcaption aria-hidden="true">Abbildung 4: Informationen zu Förderern
und Methoden in Google Dataset Search und PANGAEA (Sample von 10.000
Metadatensätzen)</figcaption>
</figure>
<p>Informationen zu Fördermitteln sind in PANGAEA etwas häufiger
vorhanden als in Google Dateset Search; aber auch in PANGAEA sind diese
Angaben nicht weit verbreitet. Unterschiede zwischen den beiden
DR-Systemen zeigen sich besonders deutlich in der Verfügbarkeit von
Informationen zu Methoden, die der Datenerhebung zugrunde liegen.
Während diese Angaben in PANGAEA für fast alle Datensätze vorliegen
(96,02 % ; n = 9.602), fehlen sie in Google Dataset Search komplett.</p>
<h3 id="diskussion">Diskussion</h3>
<p>DR ist ein schnell wachsendes Forschungsfeld innerhalb von IR, was
sicher von der steigenden Anzahl verfügbarer Datensätze durch
Open-Science-Initiativen beeinflusst wird.<br />
DR-Systeme orientieren sich bisher stark an IR-Systemen, werden jedoch
nicht immer den objekttypspezifischen Anforderungen gerecht, die
Datensätze mit sich bringen können. Zu den aktuellen Herausforderungen
im Bereich DR zählt das Fehlen von Suchansätzen, die über Keywordsuche
und Filteroptionen hinausgehen, sowie der Fokus auf strukturierte
Metadaten, da Metadaten für Forschungsdaten nicht immer in ausreichendem
Umfang vorliegen oder Qualitätsanforderungen beziehungsweise
Informationsbedürfnissen entsprechen. Auch stellt der Mangel an
spezialisierten Evaluationskonzepten für DR-Systeme ein Problem dar. Nur
wenige Repositorienbetreiber*innen haben ihr DR-System in der
Vergangenheit evaluiert. Dadurch fehlen beispielsweise gesicherte
Erkenntnisse über die Eignung des DR-Systems für das erfolgreiche
Auffinden geeigneter Datensätze, und damit auch Ansätze für die
Verbesserung des Dienstes.</p>
<p>Die Suche nach Daten unterscheidet sich in einigen Aspekten von der
Suche nach Textpublikationen. Darum ist es wichtig, das
Informationsverhalten von Datensuchenden gezielt zu betrachten. In den
vergangenen Jahren gab es eine Reihe von Vorhaben mit dieser
Zielsetzung, vor allem in den Sozialwissenschaften. Die Ergebnisse
zeigen, dass Datensuchende auf verschiedene Quellen zurückgreifen, auch
in Kombination. Dabei nutzen sie nicht nur spezialisierte
Datensuchdienste, sondern auch persönliche Kontakte oder Verweise in
Textpublikationen. Auch Websuchmaschinen werden bei der Datensuche
häufig genutzt. Bei der Nutzung von Websuchmaschinen fallen Muster wie
das Ergänzen der Suchanfrage um Begriffe wie <q>data</q> oder die Namen
bekannter Datenrepositorien auf. Suchanfragen in spezialisierten
Datensuchdiensten beinhalten häufig Einschränkungen, die sich auf
bestimmte Eigenschaften von Datensätzen beziehen, beispielsweise die
räumliche oder zeitliche Abdeckung. Eine verbreitete Strategie scheint
das bewusste Formulieren kurzer Anfragen zu sein, um lange Trefferlisten
zu erzeugen, die dann manuell geprüft werden. Insgesamt sollten
spezialisierte Datensuchdienste stärker beworben werden, damit
Forschende wissen, wo sie geeignete Daten finden können.</p>
<p>Wie für die Suche nach Textpublikationen haben sich verschiedene
Arten von Suchdiensten herausgebildet, die sich beispielsweise im Umfang
der indexierten Datenquellen (zentral – dezentral) und dem disziplinären
Fokus (disziplinspezifisch – disziplinübergreifend) unterscheiden.
Disziplinspezifische und zentrale DR-Systeme wie PANGAEA können stärker
als disziplinübergreifende oder dezentrale Dienste (zum Beispiel Google
Dataset Search) auf spezielle Informationsbedürfnisse ihrer Nutzenden
eingehen, was sich beispielsweise an den durchsuchbaren Metadaten, den
zur Verfügung gestellten Sucheinstiegen und der Präsentation der
Ergebnisse zeigt. Der Vorteil von dezentralen Diensten ist, dass sie
mehrere Datenbestände aggregieren und durchsuchbar machen. Sie können
zwar nicht auf spezielle Informationsbedürfnisse eingehen, schaffen aber
schwellenarme und bestandsübergreifende Angebote für DR. Dadurch tragen
sie zu einer besseren Sichtbarkeit von Datensätzen bei, was auch im
Interesse von Repositorien wie PANGAEA ist.</p>
<p>Metadaten der Datensätze, die in PANGAEA publiziert wurden, werden
auch von Google Dataset Search indexiert. Der Metadatenaustausch
zwischen den Diensten ist sehr effektiv, denn der Beschreibungsgrad von
PANGAEA-Datensätzen in Google Datasest Search ist verglichen mit anderen
Datenquellen überdurchschnittlich gut. So sind Informationen über
Autor*innen nur für 14,2 % aller Datensätze im untersuchten Subset von
Google Dataset Search vorhanden (Benjelloun, Chen und Noy 2020), während
die Angabe für mehr als 90 % der PANGAEA-Datensätze vorliegen. Die
Analyse zeigte jedoch, dass Informationen zu Erhebungsmethoden nicht in
vollständigem Umfang weitergegeben werden. Eine mögliche Erklärung dafür
könnte sein, dass PANGAEA zu dem Zeitpunkt, an dem das Subset erstellt
wurde (2020), das Mapping zwischen dem Metadatenschemata PANGAEA
MetaData und schema.org noch nicht optimiert hatte. Dadurch könnten
Informationen zur angewendeten Methode, die intern vorhanden sind, nicht
in die landing pages eingebettet und darum nicht von Crawls erfasst
werden.</p>
<p>Metadatenelemente, die in Google Dataset Search genutzt werden, sind
überwiegend beschreibend und nicht sehr umfangreich. Sie dienen der
Auffindbarkeit, indem identifizierende Eigenschaften (zum Beispiel
Titel, Autor*in) sowie der Kontext (zum Beispiel räumliche und zeitliche
Abdeckung) abgebildet werden. Demgegenüber können Forschungsdaten in
PANGAEA durch ein detailliertes Metadatenschema deutlich präziser
beschrieben werden. Darüber hinaus werden bei PANGAEA kontrollierte
Vokabulare eingesetzt, die semantische Bezüge zwischen Datensätzen
herstellen und die Interoperabilität verbessern.</p>
<h3 id="fazit">Fazit</h3>
<p>Durch die zunehmende Verfügbarkeit von publizierten Forschungsdaten
gewinnt Dataset Retrieval an Bedeutung. Aktuell findet das Thema viel
Aufmerksamkeit in der Forschung, zum Beispiel mit Blick auf die
Anpassung von Suchdiensten an objekttypspezifische Besonderheiten von
Forschungsdaten oder das Informationsverhalten von Datensuchenden. Auch
wenn der Metadatenaustausch nicht immer reibungslos abläuft, entwickelt
sich nach und nach ein Ökosystem ineinandergreifender DR-Systeme. Einige
sind stark an die Bedürfnisse von Datensuchenden angepasst, während
andere mehrere Datenbestände aggregieren und schwellenarme Sucheinstiege
anbieten. DR-Systeme vereinfachen das Auffinden von Forschungsdaten für
die Nachnutzung und tragen so zum Erfolg von Open-Science-Initiativen
bei.</p>
<h4 id="limitationen">Limitationen</h4>
<p>Der Vergleich der hier vorgestellten Dienste basiert unter anderem
auf einem Subset, das Google Dataset Search 2020 veröffentlicht und
seither nicht aktualisiert hat. Metadaten von PANGAEA wurden
demgegenüber 2022 gesammelt. Aufgrund dieser zeitlichen Differenz muss
der Vergleich als ungefähre Annäherung gelten, die verdeutlichen soll,
dass der Metadatenaustausch zwischen Diensten nicht immer reibungslos
abläuft.</p>
<h3 id="anhang-a">Anhang A</h3>
<table>
<caption>Tabelle 1: Beschreibung der Metadatenelemente in Google Dataset
Search und deren Vorkommen für PANGAEA-Datensätze</caption>
<colgroup>
<col style="width: 13%" />
<col style="width: 53%" />
<col style="width: 15%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="header">
<th><strong>Element</strong></th>
<th><strong>Beschreibung</strong></th>
<th style="text-align: right;"><strong>Verwendung (total)</strong></th>
<th style="text-align: right;"><strong>Verwendung
(anteilig)</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>dateModified</td>
<td>Zeitpunkt, zu dem der Datensatz zuletzt bearbeitet wurde</td>
<td style="text-align: right;">36.4255</td>
<td style="text-align: right;">100 %</td>
</tr>
<tr class="even">
<td>description</td>
<td>Beschreibung des Datensatzes</td>
<td style="text-align: right;">36.4255</td>
<td style="text-align: right;">100 %</td>
</tr>
<tr class="odd">
<td>doi</td>
<td>DOI des Datensatzes</td>
<td style="text-align: right;">36.4255</td>
<td style="text-align: right;">100 %</td>
</tr>
<tr class="even">
<td>name</td>
<td>Titel des Datensatzes</td>
<td style="text-align: right;">36.4255</td>
<td style="text-align: right;">100 %</td>
</tr>
<tr class="odd">
<td>url</td>
<td>URL des Datensatzes</td>
<td style="text-align: right;">36.4255</td>
<td style="text-align: right;">100 %</td>
</tr>
<tr class="even">
<td>distribution</td>
<td>Angaben zum Download des Datensatzes</td>
<td style="text-align: right;">36.4221</td>
<td style="text-align: right;">99,99 %</td>
</tr>
<tr class="odd">
<td>provider</td>
<td>Organisation, die den Datensatz zur Verfügung stellt</td>
<td style="text-align: right;">358.051</td>
<td style="text-align: right;">98,3 %</td>
</tr>
<tr class="even">
<td>author</td>
<td>Autor*innen des Datensatzes</td>
<td style="text-align: right;">353.825</td>
<td style="text-align: right;">97,14 %</td>
</tr>
<tr class="odd">
<td>spatialCoverage</td>
<td>Räumliche Abdeckung des Datensatzes</td>
<td style="text-align: right;">333.179</td>
<td style="text-align: right;">91,47 %</td>
</tr>
<tr class="even">
<td>isAccessibleForFree</td>
<td>Indikator, der angibt, ob der Datensatz frei verfügbar ist</td>
<td style="text-align: right;">329.631</td>
<td style="text-align: right;">90,49 %</td>
</tr>
<tr class="odd">
<td>variablesMeasured</td>
<td>Gemessene Variablen, die im Datensatz repräsentiert werden</td>
<td style="text-align: right;">312.664</td>
<td style="text-align: right;">85,84 %</td>
</tr>
<tr class="even">
<td>temporalCoverage</td>
<td>Zeitliche Abdeckung des Datensatzes</td>
<td style="text-align: right;">269.335</td>
<td style="text-align: right;">73,49 %</td>
</tr>
<tr class="odd">
<td>funder</td>
<td>Fördermittel, die zur Erhebung des Datensatzes zur Verfügung
gestellt wurden</td>
<td style="text-align: right;">37.269</td>
<td style="text-align: right;">10,23 %</td>
</tr>
<tr class="even">
<td>sameAs</td>
<td>Alternative URL des Datensatzes</td>
<td style="text-align: right;">27.666</td>
<td style="text-align: right;">7,6 %</td>
</tr>
<tr class="odd">
<td>alternateName</td>
<td>Alternativer Titel des Datensatzes</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0 %</td>
</tr>
<tr class="even">
<td>identifier</td>
<td>Identifier (außer DOI) des Datensatzes</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0 %</td>
</tr>
<tr class="odd">
<td>measurementTechnique</td>
<td>Methode, die zur Messung der repräsentierten Variablen angewendet
wurde</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">0 %</td>
</tr>
</tbody>
</table>
<h3 id="literaturverzeichnis">Literaturverzeichnis</h3>
<p>Benjelloun, Omar, Shiyu Chen, und Natasha Noy. 2020. <q>Google
Dataset Search by the Numbers.</q> In <em>The Semantic Web – ISWC
2020</em>, edited by Jeff Pan, Valentina Tamma, Claudia d’Amato,
Krzysztof Janowicz, Bo Fu, Axel Polleres, Oshani Seneviratne, und Lalana
Kagal, 667–82. Lecture Notes in Computer Science. Springer International
Publishing. <a href="https://doi.org/10.1007/978-3-030-62466-8_41"
class="uri">https://doi.org/10.1007/978-3-030-62466-8_41</a>.</p>
<p>Borst, Timo, und Fidan Limani. 2020. <q>Patterns for Searching Data
on the Web Across Different Research Communities.</q> <em>LIBER
Quarterly</em> 30 (1): 1–21. <a href="https://doi.org/10.18352/lq.10317"
class="uri">https://doi.org/10.18352/lq.10317</a>.</p>
<p>Brickley, Dan, Matthew Burgess, und Natasha Noy. 2019. <q>Google
Dataset Search: Building a Search Engine for Datasets in an Open Web
Ecosystem.</q> In <em>The World Wide Web Conference</em>, 1365–75. New
York: Association for Computing Machinery. <a
href="https://doi.org/10.1145/3308558.3313685"
class="uri">https://doi.org/10.1145/3308558.3313685</a>.</p>
<p>Canino, Adrienne. 2019. <q>Deconstructing Google Dataset Search.</q>
<em>Public Services Quarterly</em> 15 (3): 248–55. <a
href="https://doi.org/10.1080/15228959.2019.1621793"
class="uri">https://doi.org/10.1080/15228959.2019.1621793</a>.</p>
<p>Carevic, Zeljko, Dwaipayan Roy, und Philipp Mayr. 2020.
<q>Characteristics of Dataset Retrieval Sessions: Experiences from a
Real-Life Digital Library.</q> In <em>Digital Libraries for Open
Knowledge</em>, edited by Mark Hall, Tanja Merčun, Thomas Risse, und
Fabien Duchateau, 185–93. Lecture Notes in Computer Science. Springer.
<a href="https://doi.org/10.1007/978-3-030-54956-5_14"
class="uri">https://doi.org/10.1007/978-3-030-54956-5_14</a>.</p>
<p>Chapman, Adriane, Elena Simperl, Laura Koesten, George
Konstantinidis, Luis-Daniel Ibáñez, Emilia Kacprzak, und Paul Groth.
2020. <q>Dataset Search: A Survey.</q> <em>The VLDB Journal</em> 29 (1):
251–72. <a href="https://doi.org/10.1007/s00778-019-00564-x"
class="uri">https://doi.org/10.1007/s00778-019-00564-x</a>.</p>
<p>Chen, Jinchi, Xiaxia Wang, Gong Cheng, Evgeny Kharlamov, und Yuzhong
Qu. 2019. <q>Towards More Usable Dataset Search: From Query
Characterization to Snippet Generation.</q> In <em>Proceedings of the
28th ACM International Conference on Information and Knowledge
Management</em>, 2445–48. New York: Association for Computing Machinery.
<a href="https://doi.org/10.1145/3357384.3358096"
class="uri">https://doi.org/10.1145/3357384.3358096</a>.</p>
<p>Dede Şener, Duygu, Hasan Ogul, und Selen Basak. 2022. <q>Text-Based
Experiment Retrieval in Genomic Databases.</q> <em>Journal of
Information Science</em>, 01655515221118670. <a
href="https://doi.org/10.1177/01655515221118670"
class="uri">https://doi.org/10.1177/01655515221118670</a>.</p>
<p>Devaraju, Anusuriya, und Shlomo Berkovsky. 2018. <q>A Hybrid
Recommendation Approach for Open Research Datasets.</q> In
<em>Proceedings of the 26th Conference on User Modeling, Adaptation and
Personalization</em>, 207–11. New York, NY: Association for Computing
Machinery. <a href="https://doi.org/10.1145/3209219.3209250"
class="uri">https://doi.org/10.1145/3209219.3209250</a>.</p>
<p>Diepenbroek, Michael, Hannes Grobe, Manfred Reinke, Uwe Schindler,
Reiner Schlitzer, Rainer Sieger, und Gerold Wefer. 2002. <q>PANGAEA—an
Information System for Environmental Sciences.</q> <em>Computers &amp;
Geosciences</em> 28 (10): 1201–10. <a
href="https://doi.org/10.1016/S0098-3004(02)00039-0"
class="uri">https://doi.org/10.1016/S0098-3004(02)00039-0</a>.</p>
<p>Diepenbroek, Michael, Uwe Schindler, Robert Huber, Stéphane Pesant,
Markus Stocker, Janine Felden, Melanie Buss, und Matthias Weinrebe.
2017. <q>Terminology Supported Archiving and Publication of
Environmental Science Data in PANGAEA.</q> <em>Journal of
Biotechnology</em> 261: 177–86. <a
href="https://doi.org/10.1016/j.jbiotec.2017.07.016"
class="uri">https://doi.org/10.1016/j.jbiotec.2017.07.016</a>.</p>
<p>Friedrich, Tanja. 2020. <q>Looking for Data.</q> Dissertation,
Berlin: Humboldt Universität zu Berlin. <a
href="https://doi.org/10.18452/22173"
class="uri">https://doi.org/10.18452/22173</a>.</p>
<p>Google Dataset Search. 2020. <q>Dataset Search: Metadata for
Datasets.</q> <a
href="https://www.kaggle.com/datasets/1d97de37cb96c2c62182d22bf5924e0371933002bb7e5c46ba205b8a88de2e21"
class="uri">https://www.kaggle.com/datasets/1d97de37cb96c2c62182d22bf5924e0371933002bb7e5c46ba205b8a88de2e21</a>.</p>
<p>Gregory, Kathleen, Helena Cousijn, Paul Groth, Andrea Scharnhorst,
und Sally Wyatt. 2020. <q>Understanding Data Search as a Socio-Technical
Practice.</q> <em>Journal of Information Science</em> 46 (4): 459–75. <a
href="https://doi.org/10.1177/0165551519837182"
class="uri">https://doi.org/10.1177/0165551519837182</a>.</p>
<p>Gregory, Kathleen, Paul Groth, Helena Cousijn, Andrea Scharnhorst,
und Sally Wyatt. 2019. <q>Searching Data: A Review of Observational Data
Retrieval Practices in Selected Disciplines.</q> <em>Journal of the
Association for Information Science and Technology</em> 70 (5): 419–32.
<a href="https://doi.org/10.1002/asi.24165"
class="uri">https://doi.org/10.1002/asi.24165</a>.</p>
<p>Gregory, Kathleen, Paul Groth, Andrea Scharnhorst, und Sally Wyatt.
2020. <q>Lost or Found? Discovering Data Needed for Research.</q>
<em>Harvard Data Science Review</em> 2 (2). <a
href="https://doi.org/10.1162/99608f92.e38165eb"
class="uri">https://doi.org/10.1162/99608f92.e38165eb</a>.</p>
<p>Ibáñez, Luis-Daniel, und Elena Simperl. 2022. <q>A Comparison of
Dataset Search Behaviour of Internal Versus Search Engine Referred
Sessions.</q> In <em>ACM SIGIR Conference on Human Information
Interaction and Retrieval</em>, 158–68. New York: Association for
Computing Machinery. <a href="https://doi.org/10.1145/3498366.3505821"
class="uri">https://doi.org/10.1145/3498366.3505821</a>.</p>
<p>Kacprzak, Emilia, Laura Koesten, Luis-Daniel Ibáñez, Tom Blount, Jeni
Tennison, und Elena Simperl. 2019. <q>Characterising Dataset Search—An
Analysis of Search Logs and Data Requests.</q> <em>Journal of Web
Semantics</em> 55: 37–55. <a
href="https://doi.org/10.1016/j.websem.2018.11.003"
class="uri">https://doi.org/10.1016/j.websem.2018.11.003</a>.</p>
<p>Kacprzak, Emilia, Laura Koesten, Luis-Daniel Ibáñez, Elena Simperl,
und Jeni Tennison. 2017. <q>A Query Log Analysis of Dataset Search.</q>
In <em>Web Engineering</em>, edited by Jordi Cabot, Roberto De Virgilio,
und Riccardo Torlone, 429–36. Lecture Notes in Computer Science.
Springer. <a href="https://doi.org/10.1007/978-3-319-60131-1_29"
class="uri">https://doi.org/10.1007/978-3-319-60131-1_29</a>.</p>
<p>Kern, Dagmar, und Brigitte Mathiak. 2015. <q>Are There Any
Differences in Data Set Retrieval Compared to Well-Known Literature
Retrieval?</q> In <em>Research and Advanced Technology for Digital
Libraries</em>, edited by Sarantos Kapidakis, Cezary Mazurek, und Marcin
Werla, 197–208. Lecture Notes in Computer Science. Springer. <a
href="https://doi.org/10.1007/978-3-319-24592-8_15"
class="uri">https://doi.org/10.1007/978-3-319-24592-8_15</a>.</p>
<p>Khalsa, SiriJodha, Peter Cotroneo, und Mingfang Wu. 2018. <q>A Survey
of Current Practices in Data Search Services.</q> <a
href="https://doi.org/10.17632/7j43z6n22z.1"
class="uri">https://doi.org/10.17632/7j43z6n22z.1</a>.</p>
<p>Koesten, Laura M., Emilia Kacprzak, Jenifer F. A. Tennison, und Elena
Simperl. 2017. <q>The Trials and Tribulations of Working with Structured
Data: -a Study on Information Seeking Behaviour.</q> In <em>Proceedings
of the 2017 CHI Conference on Human Factors in Computing Systems</em>,
1277–89. New York: Association for Computing Machinery. <a
href="https://doi.org/10.1145/3025453.3025838"
class="uri">https://doi.org/10.1145/3025453.3025838</a>.</p>
<p>Krämer, Thomas, Andrea Papenmeier, Zeljko Carevic, Dagmar Kern, und
Brigitte Mathiak. 2021. <q>Data-Seeking Behaviour in the Social
Sciences.</q> <em>International Journal on Digital Libraries</em> 22
(2): 175–95. <a href="https://doi.org/10.1007/s00799-021-00303-0"
class="uri">https://doi.org/10.1007/s00799-021-00303-0</a>.</p>
<p>Kunze, Sven, und Sören Auer. 2013. <q>Dataset Retrieval.</q> In, 1–8.
<a href="https://doi.org/10.1109/ICSC.2013.12"
class="uri">https://doi.org/10.1109/ICSC.2013.12</a>.</p>
<p>Luk, Robert. 2022. <q>Why Is Information Retrieval a Scientific
Discipline?</q> <em>Foundations of Science</em> 27 (2): 427–53. <a
href="https://doi.org/10.1007/s10699-020-09685-x"
class="uri">https://doi.org/10.1007/s10699-020-09685-x</a>.</p>
<p>Masson, Arnaud, Guido De Marchi, Bruno Merin, Maria Sarmiento, David
Wenzel, und Beatriz Martinez. 2021. <q>Google Dataset Search and DOI for
Data in the ESA Space Science Archives.</q> <em>Advances in Space
Research</em> 67 (8): 2504–16. <a
href="https://doi.org/10.1016/j.asr.2021.01.035"
class="uri">https://doi.org/10.1016/j.asr.2021.01.035</a>.</p>
<p>Meadow, Charles, Bert Boyce, Donald Kraft, und Carol Barry. 2007.
<em>Text Information Retrieval Systems</em>. Cambridge, MA: Academic
Press.</p>
<p>Noy, Natasha, und Omar Benjelloun. 2020. <q>An Analysis of Online
Datasets Using Dataset Search.</q> <em>Google AI Blog</em>. <a
href="http://ai.googleblog.com/2020/08/an-analysis-of-online-datasets-using.html"
class="uri">http://ai.googleblog.com/2020/08/an-analysis-of-online-datasets-using.html</a>.</p>
<p>Roy, Dwaipayan, Zeljko Carevic, und Philipp Mayr. 2022. <q>Studying
Retrievability of Publications und Datasets in an Integrated Retrieval
System.</q> In <em>Proceedings of the 22nd ACM/IEEE Joint Conference on
Digital Libraries</em>, 1–9. New York, NY: Association for Computing
Machinery. <a href="https://doi.org/10.1145/3529372.3530931"
class="uri">https://doi.org/10.1145/3529372.3530931</a>.</p>
<p>Sanderson, Mark, und Bruce Croft. 2012. <q>The History of Information
Retrieval Research.</q> <em>Proceedings of the IEEE</em> 100 (Special
Centennial Issue): 1444–51. <a
href="https://doi.org/10.1109/JPROC.2012.2189916"
class="uri">https://doi.org/10.1109/JPROC.2012.2189916</a>.</p>
<p>Sun, Guangyuan, Tanja Friedrich, Kathleen Gregory, und Brigitte
Mathiak. 2022. <q>Are We Building the Data Discovery Infrastructure
Researchers Want? Comparing Perspectives of Support Specialists und
Researchers.</q> arXiv. <a
href="https://doi.org/10.48550/arXiv.2209.14655"
class="uri">https://doi.org/10.48550/arXiv.2209.14655</a>.</p>
<p>Wang, Xu, Zhisheng Huang, und Frank van Harmelen. 2020. <q>Evaluating
Similarity Measures for Dataset Search.</q> In <em>Web Information
Systems Engineering – WISE 2020</em>, edited by Zhisheng Huang, Wouter
Beek, Hua Wang, Rui Zhou, und Yanchun Zhang, 38–51. Springer. <a
href="https://doi.org/10.1007/978-3-030-62008-0_3"
class="uri">https://doi.org/10.1007/978-3-030-62008-0_3</a>.</p>
<p>Wu, Mingfang, Fotis Psomopoulos, Siri Jodha Khalsa, und Anita de
Waard. 2019. <q>Data Discovery Paradigms: User Requirements and
Recommendations for Data Repositories.</q> <em>Data Science Journal</em>
18 (1): 3. <a href="https://doi.org/10.5334/dsj-2019-003"
class="uri">https://doi.org/10.5334/dsj-2019-003</a>.</p>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>PANGAEA Terms of Use: <a
href="https://www.pangaea.de/about/terms.php"
class="uri">https://www.pangaea.de/about/terms.php</a><a href="#fnref1"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Es werden verschiedene Schnittstellen angeboten, siehe
die API-Dokumentation: <a
href="https://ws.pangaea.de/"
class="uri">https://ws.pangaea.de/</a><a href="#fnref2"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>PANGAEA Data Warehouse: <a
href="https://www.pangaea.de/tools/"
class="uri">https://www.pangaea.de/tools/</a><a href="#fnref3"
class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>PANGAEA MetaData: <a
href="http://ws.pangaea.de/schemas/pangaea/MetaData.xsd"
class="uri">http://ws.pangaea.de/schemas/pangaea/MetaData.xsd</a><a
href="#fnref4" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<hr />
<p><strong>Dorothea Strecker</strong> ist Wissenschaftliche
Mitarbeiterin im Projekt re3data COREF am Institut für Bibliotheks- und
Informationswissenschaft der Humboldt-Universität zu Berlin.</p></div>

    

</article>




        <footer class="footer">
<hr>
<p><a href="https://creativecommons.org/licenses/by/4.0/">All content licensed under Creative Commons Attribution 4.0 International (CC BY 4.0)</a>, if not otherwise stated.
</p>
<p>LIBREAS. Library Ideas wird herausgegeben am <a href="https://www.ibi.hu-berlin.de/">Institut für Bibliotheks- und Informationswissenschaft</a> der <a href="https://www.hu-berlin.de/">Humboldt-Universität zu Berlin</a></p>
<p>Hosted on <a href="http://github.com/libreas/libreas.github.io">GitHub</a>, made with <a href="http://octopress.org/">Jekyll/Octopress</a> and <a href="http://johnmacfarlane.net/pandoc/">pandoc</a></p>

<p>ISSN: 1860-7950</p>


    LIBREAS. Library Ideas

(last updated: <a href="https://github.com/libreas/libreas.github.io/commits/master">2023-12-22</a>)</p>

</footer>
      </div>
    </div>
<label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  </body>
</html>
