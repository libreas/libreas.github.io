
<!DOCTYPE HTML>

<html>

<head>
	<meta charset="utf-8">
	<title>Vorschrift oder Thunfisch? &ndash; Zur Langzeitverf&uuml;gbarkeit von Forschungsdaten - LIBREAS. Library Ideas</title>
	<meta name="author" content="LIBREAS. Library Ideas">


<!-- RDFa DC -->

 <!-- RDFa Metadata (in DublinCore) -->
    
    <meta property="dc:title" content="Vorschrift oder Thunfisch? &amp;ndash; Zur Langzeitverf&amp;uuml;gbarkeit von Forschungsdaten" />
    
    
    
    <meta property="dc:creator" content="Tim Hasler" />
    
    <meta property="dc:creator" content="Wolfgang Peters-Kottig" />
    
    
    
    <meta property="dc:date" content="2013" />
    
    <meta property="dc:format" content="text/html" />
    <meta property="dc:language" content="de" />
    <meta property="dc:identifier" content="https://libreas.eu/ausgabe23/08hasler/index.html" />
    
    <meta property="dc:rights" prefix="cc: http://creativecommons.org/ns#" rel="cc:license" href="https://creativecommons.org/licenses/by/4.0/" content="CC-BY 4.0" />
	
    <meta property="dc:source" content="LIBREAS. Library Ideas" />
    <meta property="dc:subject" content="Library and Information Science" />
    <meta property="dc:type" content="website" />
    <meta property="dc:description" content="&amp;bdquo;Ich mache ihm ein Angebot, das er nicht ablehnen kann.&amp;rdquo; Diese Aussage aus einem g&amp;auml;nzlich anderen Kontext l&amp;auml;sst sich recht treffend &amp;uuml;bertragen als Wunsch von Dienstleistern und Zweck von Dienstleistungen f&amp;uuml;r Datenproduzenten im Forschungsdatenmanagement. Zwar wirkt Druck zur Daten&amp;uuml;bergabe nicht f&amp;ouml;rderlich, die Er&amp;ouml;ffnung einer Option aber sehr wohl. Im vorliegenden Artikel geht es um das Verst&amp;auml;ndnis der Nachhaltigkeit von Forschung und ihren Daten anhand der Erkenntnisse und Erfahrungen aus der ersten Phase des DFG-Projekts EWIG. [&lt;a name=&quot;fn01b&quot;&gt;&lt;/a&gt;&lt;a href=&quot;#fn01&quot;&gt;Fn 01&lt;/a&gt;] Eine Auswahl von Fallstricken beim Forschungsdatenmanagement wird anhand der Erkenntnisse aus Expertengespr&amp;auml;chen und eigenen Erfahrungen beim Aufbau von LZA-Workflows vorgestellt. Erste Konzepte in EWIG zur Daten&amp;uuml;bertragung aus unterschiedlich strukturierten Datenquellen in die &amp;bdquo;Langfristige Dom&amp;auml;ne&amp;rdquo; werden beschrieben."/>
    <meta property="dc:source" resource="urn:ISSN:1860-7950" /> 

<!-- Google Scholar -->

	<meta name="citation_journal_title" content="LIBREAS. Library Ideas" />
	<meta name="citation_issue" content="23" />
	<meta name="citation_issn" content="1860-7950" />
	
    <meta name="citation_publication_date" content="2013" />
    


  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

	<link href="/atom.xml" rel="alternate" title="LIBREAS. Library Ideas" type="application/atom+xml">
	
	<link rel="canonical" href="https://libreas.eu/ausgabe23/08hasler/">
	<link href="/favicon.png" rel="shortcut icon">
	<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">


    <!--   
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="favicon.png"> -->
  
	
</head>




  <body class="theme-base-wes">

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <a href="/">LIBREAS. Library Ideas</a>
  </div>

  <nav class="sidebar-nav">

    	<a class="sidebar-nav-item" href="/ausgabe40/">Aktuelle Ausgabe</a>
	<a class="sidebar-nav-item" href="/archiv.htm">Archiv</a>
	<a class="sidebar-nav-item" href="http://edoc.hu-berlin.de/browsing/libreas/">edoc pdf-Archiv</a>
	<a class="sidebar-nav-item" href="/autorinnen">Autor*innen</a>
	<a class="sidebar-nav-item" href="http://libreas.wordpress.com/category/libreas-call-for-papers/">Call for Papers</a>
	<a class="sidebar-nav-item" href="/authorguides">Author guidelines</a>
	<a class="sidebar-nav-item" href="http://libreas.wordpress.com/">Blog</a>
	<a class="sidebar-nav-item" href="http://libreas.tumblr.com/">Tumblr</a>
    <a class="sidebar-nav-item" href="https://www.zotero.org/groups/4620604/">Zotero DLDL</a>
	<a class="sidebar-nav-item" href="https://web.archive.org/web/20171112100417/http://www.ib.hu-berlin.de/~libreas/libreas_neu/podcasts/">Podcasts</a>
	<a class="sidebar-nav-item" href="http://libreas-verein.eu">Verein</a>
	<a class="sidebar-nav-item" href="/about">Impressum</a>

  </nav>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <!-- <div class="wrap">
       <div class="masthead">
        <div class="container">
          <h1 class="masthead-title">
            <a href="/" title="Home">LIBREAS. Library Ideas</a>
            <small><br></small>
          </h1>
        </div>
      </div> -->


      <div class="container content">
      <!-- GitHub et al icon -->
      <div align="right" class="icons">
        <a href="mailto:redaktion@libreas.eu"><i class="fa fa-envelope"></i></a>
        <a href="https://github.com/libreas"><i class="fa fa-github-square"></i></a>
        <a href="https://www.instagram.com/libreas.libraryideas/"><i class="fa fa-instagram"></i></a>
        <a href="https://twitter.com/libreas"><i class="fa fa-twitter"></i></a>
        <a href="https://github.com/libreas.atom"><i class="fa fa-rss"></i></a>
</div>
        
<article class="page" itemscope itemtype="http://schema.org/ScholarlyArticle">

<div align="right">

<strong> > > > <a href="/ausgabe23/00inhalt/">LIBREAS. Library Ideas # 23</a></strong> <br><br></div>




    
    <div align="right">
    <p><small><a itemprop="sameAs" href="https://via.hypothes.is/https://libreas.eu/ausgabe23/08hasler/">Annotate via hypothes.is</a></small></p>
        <small><a itemprop="sameAs" href="http://nbn-resolving.de/urn:nbn:de:kobv:11-100212717">Download PDF @ edoc HU Berlin</a>
            <br>
            urn:nbn:de:kobv:11-100212717 </small>
        </div>
        
    
    
        

        
        <h1 itemprop="name" class="title">Vorschrift oder Thunfisch? &ndash; Zur Langzeitverf&uuml;gbarkeit von Forschungsdaten</h1>
        
        <h2><small></small></h2>
        
        

        <div class="titelei">
        
        <i itemprop="author">Tim Hasler, Wolfgang Peters-Kottig</i>
        
    </div>

<!-- 

        
        <div class="titelei">
            
              
              
            <i itemprop="author">Tim Hasler</i> 
            
            
               
            </i><i itemprop="author">Wolfgang Peters-Kottig</i>
            
            
            
        </div>
 -->



        

        <p><small itemprop="description">&bdquo;Ich mache ihm ein Angebot, das er nicht ablehnen kann.&rdquo; Diese Aussage aus einem g&auml;nzlich anderen Kontext l&auml;sst sich recht treffend &uuml;bertragen als Wunsch von Dienstleistern und Zweck von Dienstleistungen f&uuml;r Datenproduzenten im Forschungsdatenmanagement. Zwar wirkt Druck zur Daten&uuml;bergabe nicht f&ouml;rderlich, die Er&ouml;ffnung einer Option aber sehr wohl. Im vorliegenden Artikel geht es um das Verst&auml;ndnis der Nachhaltigkeit von Forschung und ihren Daten anhand der Erkenntnisse und Erfahrungen aus der ersten Phase des DFG-Projekts EWIG. [<a name="fn01b"></a><a href="#fn01">Fn 01</a>] Eine Auswahl von Fallstricken beim Forschungsdatenmanagement wird anhand der Erkenntnisse aus Expertengespr&auml;chen und eigenen Erfahrungen beim Aufbau von LZA-Workflows vorgestellt. Erste Konzepte in EWIG zur Daten&uuml;bertragung aus unterschiedlich strukturierten Datenquellen in die &bdquo;Langfristige Dom&auml;ne&rdquo; werden beschrieben.</small></p>

        

        

        <br>

        <p><small itemprop="description"> &quot;I'm gonna make him an offer he can't refuse&quot;. This quote from a completely different context can be aptly rendered as a statement of service providers as well as the purpose of services for data producers in the field of research data management. Although pressure is not the leverage of choice if you want researchers to deposit their research data in some kind of repository, offering an option does the trick quite well. In this article we present some of the concepts for sustainability of research and its data from the first phase the of the project EWIG, funded by the Deutsche Forschungsgemeinschaft. A selection of pitfalls in research data management is presented based on the findings from expert interviews and our own experiences in the construction of LTP workflows. First concepts in EWIG to transfer data from differently structured data sources into the &quot;Permanent Domain&quot; are described.</small></p>

        



        
        <p>
          <small>
            <br>
            Zitiervorschlag
            <br>
            
            
            Tim Hasler,
            
            
            
            Wolfgang Peters-Kottig,
            
            
            
            "Vorschrift oder Thunfisch? &ndash; Zur Langzeitverf&uuml;gbarkeit von Forschungsdaten. ".
            
            <i itemprop="provider">LIBREAS. Library Ideas</i>, 23 (<span itemprop="datePublished">2013</span>). <a itemprop="url" href="https://libreas.eu/ausgabe23/08hasler/">https://libreas.eu/ausgabe23/08hasler/</a>
        </small>
        <hr>
    </p>
   
    





    <div class="entry-content" itemprop="articleBody">	<ul>
     <li><a href="#1" class="inhaltsverzeichnis">Wo hapert es bei der Langzeitarchivierung von Forschungsdaten? &ndash; Erkenntnisse aus Expertengespr&auml;chen</a></li>
     <li><a href="#2" class="inhaltsverzeichnis">Exemplarische &Uuml;bergabeworkflows</a></li>
	 <li><a href="#3" class="inhaltsverzeichnis">Fachspezifische Lehrmodule</a></li>
    </ul>
	
	<p>Die nachfolgende Szene spielt in einem beliebigen Forschungsinstitut kleineren Zuschnitts ohne Anbindung an ein World Data Center wie das WDC Climate [<a name="fn02b"></a><a href="#fn02">Fn 02</a>], WDC-Mare/Pangaea [<a name="fn03b"></a><a href="#fn03">Fn 03</a>] oder ein anderes Forschungsdaten-Repositorium. [<a name="fn04b"></a><a href="#fn04">Fn 04</a>] Ein Wissenschaftler arbeitet in seiner Arbeitsgruppe zum Teil mit Daten dieser Gruppe, zum Teil mit eigenen Daten, zum Teil mit Daten anderer Wissenschaftler seiner oder einer anderen Community. [<a name="fn05b"></a><a href="#fn05">Fn 05</a>] Sp&auml;testens zum Zeitpunkt des Projektendes kommt dann die Frage auf: &bdquo;Wohin mit den zu sichernden Daten&rdquo;? [<a name="fn06b"></a><a href="#fn06">Fn 06</a>] In diesem harmlos erscheinenden Satz sind bereits mehrere Fallstricke mit Bezug auf schl&uuml;ssiges Datenmanagement verborgen: &bdquo;Projektende&rdquo;, &bdquo;zu sichernde Daten&rdquo; und &bdquo;wohin&rdquo;.</p>
	<p>Erster Fallstrick: &bdquo;Projektende&rdquo;. Zu diesem Zeitpunkt sind die Mitarbeiter in der Regel bereits mit dem n&auml;chsten Projekt befasst oder haben gar die Institution gewechselt. Wenn erst zu diesem Zeitpunkt mit der Auswahl und Bewertung der langfristig zu bewahrenden Daten begonnen wird (zweiter Fallstrick), ist die Motivation zur geeigneten Anreicherung mit Metadaten gemeinhin gering. Als Beispiel sei ein im Wissenschaftsbetrieb der Universit&auml;ten allgegenw&auml;rtiges Problem genannt: Im Fall von Abschlussarbeiten wie Dissertationen ist trotz Aufbewahrungspflicht nach den Empfehlungen zur Sicherung der guten Wissenschaftlichen Praxis und den Vorgaben einer Pr&uuml;fungsordnung in kaum einer Institution ein geordnetes System etabliert, um digitale Forschungsergebnisse solcher Arbeiten angemessen vorzuhalten (dritter Fallstrick). [<a name="fn07b"></a><a href="#fn07">Fn 07</a>]</p>
	<p>Seitdem von Seiten der F&ouml;rderorganisationen sanfter (und voraussichtlich weiter steigender) Druck auf die Datenproduzenten ausge&uuml;bt wird, ein Konzept f&uuml;r die Sicherung erzeugter Daten vorzulegen, [<a name="fn08b"></a><a href="#fn08">Fn 08</a>] wird dieser Druck auch f&uuml;r die (potentiellen) Dienstleister kontinuierlich gr&ouml;&szlig;er werden, sofern sie keine eigene initiative L&ouml;sung anbieten. Am Ende dieser De-Motivationskette steht allerdings noch das Wie.</p>
	<p>Dieser Beitrag stellt Erkenntnisse und Erfahrungen verschiedener Akteure im Forschungsdatenmanagement mit der &Uuml;bernahme und &Uuml;bergabe von Daten dar und beleuchtet konkrete Schwierigkeiten, mit denen sich Infrastruktureinrichtungen konfrontiert sehen, wenn sie (Forschungs-)Daten in die dauerhafte Dom&auml;ne [<a name="fn09b"></a><a href="#fn09">Fn 09</a>] &uuml;berf&uuml;hren wollen. Die Identifizierung dieser Schwierigkeiten war Projektinhalt in der ersten F&ouml;rderphase des DFG-Projekts EWIG.</p>

	<a name="1" id="1"></a><h3>Wo hapert es bei der Langzeitarchivierung von Forschungsdaten? &ndash; Erkenntnisse aus Expertengespr&auml;chen</h3>
	<p>Organisatorische Fragen bei der Sicherung der Langzeitverf&uuml;gbarkeit [<a name="fn10b"></a><a href="#fn10">Fn 10</a>] von Forschungsdaten treten gegen&uuml;ber den technischen Problemen zunehmend in den Vordergrund. Dennoch sind bei weitem nicht alle technischen Probleme gel&ouml;st &ndash; die technische Qualit&auml;tssicherung an der &Uuml;bergabeschnittstelle an ein Langzeitarchiv oder Repositorium ist beispielsweise weiterhin Forschungsgegenstand. [<a name="fn11b"></a><a href="#fn11">Fn 11</a>] Qualit&auml;tsmanagement in technischer und organisatorischer Hinsicht ist ein wesentliches Kriterium bei der Bewertung des erfolgreichen Betriebs eines Langzeitarchivs oder Forschungsdatenrepositoriums. [<a name="fn12b"></a><a href="#fn12">Fn 12</a>] Aus den im Rahmen von EWIG durchgef&uuml;hrten Expertengespr&auml;chen mit Vertretern von Infrastruktureinrichtungen (&bdquo;Dienstleistern&rdquo;) und einzelnen Datenproduzenten wird dieser Zweiklang von organisatorischen und technischen Problemen deutlich. [<a name="fn13b"></a><a href="#fn13">Fn 13</a>] Im Folgenden werden charakteristische Probleme beim Forschungsdatenmanagement in disziplin&auml;ren als auch disziplin&uuml;bergreifend agierenden Einrichtungen in Deutschland skizziert. Die disziplin&uuml;bergreifend t&auml;tigen Einrichtungen (mehrheitlich Bibliotheken) sind in ihren Workflows &uuml;berwiegend mit einer objektbezogenen Verarbeitung von Datens&auml;tzen befasst. Dies beinhaltet einzelne Datenpakete wie beispielsweise JPEG-Dateien oder PDF-Dokumente mit den zugeh&ouml;rigen Metadaten.</p>
	<p>Vor allem naturwissenschaftlich ausgerichtete Institutionen arbeiten hingegen h&auml;ufig mit Tabellenwerten als Forschungsdaten, die in umfangreichen relationalen Datenbanken verwaltet werden. Hier greift das objektzentrierte Konzept der einzelnen Datenpakete nicht ohne weiteres. Der Mehraufwand, der betrieben werden muss, um etwa kontinuierlich anfallende Messdaten aus Datenbanken in definierte Pakete zu exportieren, ist nicht zu untersch&auml;tzen.</p>
	<p>Grunds&auml;tzlich gilt f&uuml;r alle im Prozess der Daten&uuml;bergabe involvierten Einrichtungen, dass die Heterogenit&auml;t der Anforderungen bei der Metadatenbeschreibung, bei der technischen und inhaltlichen Konsistenz, den Datenformaten, den Fachstandards beim Zugriff auf Forschungsdaten sowie bei den unterschiedlichen Niveaus der Datenkuratierung dazu f&uuml;hrt, dass Vereinbarungen zur Langzeitverf&uuml;gbarkeit nur bezogen auf die jeweilige Institution auf Basis individueller Policies definiert werden k&ouml;nnen. Diese sollten aus musterhaften, generalisierten Workflows/Policies abgeleitet werden k&ouml;nnen. In Deutschland sind solche Policies allerdings noch Mangelware. [<a name="fn14b"></a><a href="#fn14">Fn 14</a>]</p>
	<p>Die Qualit&auml;tssicherung an der &Uuml;bergabeschnittstelle zwischen Datenproduzent und Infrastrukturanbieter wird von beiden Seiten generell als sehr wichtige Aufgabe gesehen. Die technische Qualit&auml;tssicherung bezieht sich dabei insbesondere auf die Pr&uuml;fung von Dateiobjekten. Die inhaltliche Qualit&auml;tssicherung (QS) kann entweder durch den Datenproduzenten erfolgen oder im Austausch zwischen Datenproduzent und fachwissenschaftlich ausgebildetem Datenkurator. In den Geowissenschaften ist dies beispielsweise in den WDCs erfolgreich realisiert. [<a name="fn15b"></a><a href="#fn15">Fn 15</a>] Der Aufwand f&uuml;r die Ausbildung von fachspezifisch t&auml;tigen Datenkuratoren f&uuml;r die inhaltliche QS wird dort allerdings als sehr hoch eingesch&auml;tzt.</p>
	<p>Ein anhaltender Trend im Forschungsdatenmanagement ist die Vorverlagerung der tats&auml;chlichen Daten&uuml;bergabe weg vom Ingest-System des Dienstleisters n&auml;her an den Datenproduzenten. Aus den Gespr&auml;chen in EWIG l&auml;sst sich entnehmen, dass einige Anbieter ihren Datenlieferanten zus&auml;tzliche Softwaresysteme im Pre- oder &bdquo;Pre-Pre&rdquo;-Ingest zur Verf&uuml;gung stellen oder dies in naher Zukunft beabsichtigen. In diesen Systemen sollen Wissenschaftler ihre Daten vorbereiten, bearbeiten, erweitern, auch l&ouml;schen und erst bei Abschluss aller Arbeiten an ein Repositorium oder Archiv &uuml;bergeben k&ouml;nnen.</p>
	<p>Problematisch ist weiterhin das Fehlen eines gemeinsamen Vokabulars beim Forschungsdatenmanagement. Das Referenzmodell Open Archival Information System (OAIS) hat zur Begriffskl&auml;rung und -sch&auml;rfung f&uuml;r den Aufbau von Langzeitarchivierungssystemen beigetragen. Bei den anderen Aspekten des Forschungsdatenmanagements zeigt sich allerdings, dass kuratierende Einrichtungen, kommerzielle Anbieter und IT-Servicezentren untereinander eine andere Sprache sprechen &ndash; ganz zu schweigen von Fachwissenschaftlern, deren Fragen und Vorgaben jeweils disziplin&auml;r adressiert und &bdquo;&uuml;bersetzt&rdquo; werden m&uuml;ssen. Es scheint zudem Entwicklungsbedarf f&uuml;r den Aufbau einer einheitlichen Terminologie f&uuml;r Kostenmodelle zu geben.</p>
	<p>Eine weitere Erfahrung aus den Expertengespr&auml;chen ist das durchgehende Interesse an Lehr- und Weiterbildungsveranstaltungen f&uuml;r Wissenschaftler und Studierende mit dem Thema Langzeitverf&uuml;gbarkeit von Forschungsdaten. Vorhaben an akademischen Einrichtungen in Deutschland, Module mit dem Thema Forschungsdatenmanagement oder Langzeitverf&uuml;gbarkeit in die disziplin&auml;re Ausbildung zu integrieren, sind erst in Ans&auml;tzen vorhanden. [<a name="fn16b"></a><a href="#fn16">Fn 16</a>] Diese werden einen wesentlichen Baustein f&uuml;r die Etablierung von Datenkuratoren mit fachwissenschaftlichem Hintergrund bilden.</p>
	<p>Die befragten Fachwissenschaftler sehen durchaus Bibliotheken als Akteure im Forschungsdatenmanagement, gegebenenfalls in Kooperation mit IT-Servicezentren. Hier kommt offenbar ein &bdquo;klassisches&rdquo; Image der Bibliotheken als vertrauensw&uuml;rdige Partner der Wissenschaft zum Tragen. An verschiedenen Institutionen wie etwa der ETH Z&uuml;rich [<a name="fn17b"></a><a href="#fn17">Fn 17</a>] oder der TU Berlin [<a name="fn18b"></a><a href="#fn18">Fn 18</a>] gibt es Bestrebungen, auch den sogenannten kleineren F&auml;chern einen Platz f&uuml;r ihre Forschungsdaten zu geben &ndash; wo die wissenschaftliche Community (noch) kein disziplin&auml;res Forschungsdatenzentrum zur Verf&uuml;gung stellt, kommen die Bibliotheken als vertrauensw&uuml;rdige Institutionen in Betracht, Daten zu kuratieren &ndash; wenngleich sie ihre Rolle noch klarer definieren m&uuml;ssen. [<a name="fn19b"></a><a href="#fn19">Fn 19</a>]</p>
	<p>Aus den Expertengespr&auml;chen lie&szlig;en sich neben organisatorischen Problemen auch allgemeing&uuml;ltige technische &bdquo;L&uuml;cken in den Workflows&rdquo; identifizieren:</p>
	<blockquote>1. Unvollst&auml;ndigkeit und geringe Usability von Softwarewerkzeugen (Tools) zur Qualit&auml;tssicherung (QS) beim Ingest.</blockquote>
	<p>Unter diesem Stichpunkt lassen sich verschiedene Aspekte zusammenfassen. Vorrangig geht es beim Einsatz von Tools um die technische Qualit&auml;tssicherung hinsichtlich Integrit&auml;t und Authentizit&auml;t von Forschungsdatenpaketen, die in ein Langzeitarchiv oder Repositorium &uuml;berf&uuml;hrt werden sollen. Dabei ist es grunds&auml;tzlich gleichg&uuml;ltig, ob die Pr&uuml;fung schon durch die abliefernden Wissenschaftler (Datenproduzenten), eine Zwischeninstanz (etwa die IT-Abteilung eines Instituts) oder sp&auml;ter beim Ingest durch den Dienstleister durchgef&uuml;hrt wird. Inhalt der Qualit&auml;tssicherung ist die Pr&uuml;fung formaler Vorgaben zur Vollst&auml;ndigkeit der Lieferung, zur Informationspaketerstellung inklusive der Metadatenvergabe und zur Einhaltung des vereinbarten &Uuml;bergabewegs (zum Beispiel FTP-&Uuml;bertragung, Festplatten&uuml;bergabe) sowie die Identifizierung und Validierung des eigentlichen Objekts (Datei). Es wird gepr&uuml;ft, ob das Dateiformat identifizierbar ist und hinsichtlich der Formatspezifikation validiert werden kann. Je nach Bedarf k&ouml;nnen umfangreiche technische Metadaten aus dem verwendeten Dateiformat extrahiert und den technischen Metadaten des Pakets hinzugef&uuml;gt werden. Generell ist der Einsatz von mehr als einem Werkzeug notwendig, um Formatidentifizierung, -validierung und Metadatenextraktion m&ouml;glichst vollumf&auml;nglich durchzuf&uuml;hren. Welche der existierenden Tools dabei eingesetzt werden sollten, ist zurzeit praktisch nur in einem umst&auml;ndlichen Verfahren durch trial and error herauszufinden &ndash; Empfehlungen und Handreichungen fehlen weitgehend (vgl. Punkt 3). Problematisch ist die Qualit&auml;tssicherung vor allem, wenn sehr viele Objekte verarbeitet werden m&uuml;ssen. Zudem ist bisher nur der Bereich der textbasierten Dateiformate sowie Bilder mit Tools ann&auml;hernd umfassend &uuml;berpr&uuml;fbar. Audiovisuelle Medien k&ouml;nnen in Ans&auml;tzen schon gepr&uuml;ft werden, f&uuml;r komplexe Dateiformate fehlen noch weitgehend Tools.</p>
	<blockquote>2. Unverst&auml;ndliche, &uuml;berkomplexe oder fehlende R&uuml;ckmeldung von Ingest-Fehlern.</blockquote>
	<p>Dieses Problem betrifft sowohl die Ergebnisanzeige der Tools nach einem Pr&uuml;fvorgang (zumeist in XML) als auch die R&uuml;ckmeldung des annehmenden Dienstleisters an die abliefernden Datenproduzenten &uuml;ber einen erfolgten Ingestvorgang. Es fehlen verst&auml;ndliche, kurze Auswertungen, die die Vorg&auml;nge und Ergebnisse des Daten-Ingest auch f&uuml;r Nicht-Fachleute nachvollziehbar machen und im besten Fall Empfehlungen f&uuml;r eine verbesserte Neulieferung beinhalten, sofern gemeldete Fehler intolerabel sind. Im Zweifel werden momentan auch fehlerhafte Dateien archiviert. Gemein ist den meisten Werkzeugen ein technischer Ansatz mit ebensolcher Fehlermeldung, der allerdings Expertenwissen verlangt: Was soll ein Wissenschaftler mit der Feststellung anfangen, dass bei der Validierung seines PDFs mit JHOVE (JSTOR/Harvard Object Validation Environment) eine java.lang.exception an offset 3456.325432 hervorgerufen wurde? [<a name="fn20b"></a><a href="#fn20">Fn 20</a>] Heutige (Pre-)Ingest-Tools setzen ein tiefgehendes Verst&auml;ndnis von XML und Dateiformaten voraus.</p>
	<blockquote>3. Geringe Performanz, Pr&auml;zision und Robustheit von Werkzeugen zur Qualit&auml;tssicherung.</blockquote>
	<p>Die Validierung und Metadatenextraktion ist derzeit ein umst&auml;ndliches Verfahren, das unabh&auml;ngig von der eingesetzten Software unn&ouml;tig langsam ist, weil Dateien einzeln in einer Kette von Werkzeugen ge&ouml;ffnet werden m&uuml;ssen. Der Vorgang lie&szlig;e sich deutlich performanter gestalten. Die Frage ist nur, wer die Kapazit&auml;ten hat, diese Flei&szlig;arbeit zu &uuml;bernehmen. Es gibt eben keine nachvollziehbaren Empfehlungen dazu, welche Tools &uuml;berhaupt eingesetzt werden sollten. Online ist eine un&uuml;bersehbare Vielfalt an unkommentierten Tool Registries zu finden, die sich inhaltlich stark &uuml;berschneiden. Eine Initiative aus dem SPRUCE-Projekt innerhalb der Open Planets Foundation zum Aufbau eines konsolidierten, community-gepflegten Verzeichnisses ist &uuml;ber die Initialidee noch nicht hinausgekommen. [<a name="fn21b"></a><a href="#fn21">Fn 21</a>] Die Vergleichbarkeit von technischen Software-Werkzeugen wird zudem durch ihren unterschiedlichen Funktionsumfang und Fehleroutput erschwert. Einige Tools haben die unangenehme Eigenschaft, bei Fehlern in Dateien Pr&uuml;fl&auml;ufe abzubrechen, ohne Handlungsoptionen aufzuzeigen.</p>
	<p>Infrastruktureinrichtungen, die bereits Workflows mit technischer Qualit&auml;tssicherung anbieten, haben im Wesentlichen nur die Option, die Fehler zu ignorieren und zu dokumentieren, sofern sie keine &bdquo;starke Policy&rdquo; haben, die es erlaubt, nicht-standardkonforme Daten einfach abzulehnen (z.B. bei der Annahme von NetCDF-Daten beim WDC Climate). Daten werden h&auml;ufig trotz technischer M&auml;ngel ins Archiv oder Repositorium aufgenommen. Gegebenenfalls werden die Daten beim Ingest auf ein einheitliches Format migriert (normalisiert), das keine technischen Fehler mehr produziert. Dieser Prozess hat aber m&ouml;glicherweise Auswirkungen auf die Interpretationsf&auml;higkeit der Inhalte. Manuelle Eingriffe sind zwar gang und g&auml;be, aber f&uuml;r einen effizienten Ingest inakzeptabel. Wenn die Zeit, die Policy der Einrichtung und die Datenquelle es hergeben, kann auch der urspr&uuml;ngliche Datenproduzent um die erneute &Uuml;bermittlung einer fehlerfreien Datei gebeten werden.</p>
	<blockquote>4. Geringe Interoperabilit&auml;t zwischen Zielsystemen.</blockquote>
	<p>Datenpakete, die f&uuml;r die Ablieferung an einen Dienstanbieter konzipiert und dort in Archival Information Packages (&bdquo;AIPs&rdquo; nach der OAIS-Terminologie) &uuml;berf&uuml;hrt wurden, k&ouml;nnen kaum an andere Einrichtungen gesendet (und dort verarbeitet) werden. F&uuml;r externe Betrachter ist diese Eigenschaft nur schwer nachzuvollziehen, denn die konzeptionelle Idee hinter Informationspaketen ist gerade der kontextlos zu interpretierende Inhalt einzelner Pakete &ndash; sie sollten gleichsam als &bdquo;Zeitkapseln&rdquo; fungieren k&ouml;nnen. Der Grund f&uuml;r dieses Problem sind die sehr spezifisch eingerichteten technischen und administrativen Workflows f&uuml;r die Datenannahme, die zudem vertraglich unterschiedlich geregelt werden k&ouml;nnen. Jeder einzelne Workflow, der etwa den Einsatz von Validierungstools spezifiziert, muss genau an die Bedingungen hinsichtlich Technik, Inhalt, Community-Standard, Recht und Organisation der beteiligten Institutionen angepasst werden.</p>
	<blockquote>5. Unklarer organisatorischer Rahmen des Technology Watch.</blockquote>
	<p>Auf welcher Basis eine weltweit notwendige Vernetzung zur Organisation des Technology Watch zur Identifizierung obsolet werdender Dateiformate aufgebaut wird, ist weiterhin nicht gekl&auml;rt. Es gibt zwar Format-Registries, die abgefragt werden k&ouml;nnen, aber wer letztlich organisatorisch &uuml;ber notwendige Migrationen entscheidet beziehungsweise diese empfiehlt, muss noch gel&ouml;st werden. Aus Sicht des EWIG-Projekts wird eine L&ouml;sung sowohl f&uuml;r die Frage des Technology Watch als auch f&uuml;r die unter den Punkten 1 bis 3 angedeuteten Probleme nur langsam fortschreitend in Form community-&uuml;bergreifender Vernetzung verschiedenster nationaler und internationaler Projekte und Initiativen erfolgen. [<a name="fn22b"></a><a href="#fn22">Fn 22</a>] Bei Formaten wie NetCDF, die innerhalb der Geowissenschaften in st&auml;ndiger Beobachtung/Bearbeitung sind, wird die Entscheidung aber auch in Zukunft innerhalb der fachwissenschaftlichen Communities getroffen. Dies f&uuml;hrt, etwa am WDC Climate, zu der komfortablen Lage, dass alle Daten wie selbstverst&auml;ndlich der Spezifikation entsprechen, da sonst schlicht nicht mit ihnen gearbeitet werden k&ouml;nnte.</p>
	<p>Zu den eher technischen Workflow-L&uuml;cken kommen M&auml;ngel der inhaltlichen Beschreibung von Forschungsdaten, die nur auf Seiten der Datenproduzenten gel&ouml;st werden k&ouml;nnen, solange es keine ausgebildeten Datenkuratoren in allen Disziplinen gibt. Forschungsdatens&auml;tze enthalten nur im Idealfall ausreichende inhaltliche Metadaten bez&uuml;glich der verwendeten Ger&auml;te, der Methoden und der organisatorischen Rahmenbedingungen. Der Umfang der Datenbeschreibung ist dabei abh&auml;ngig von den Gepflogenheiten in der jeweiligen Forschungsrichtung. Weil in vielen F&auml;llen aber lediglich an die mehr oder minder unmittelbar am Thema arbeitende Forschergemeinschaft als zuk&uuml;nftigen Adressat f&uuml;r die Daten (&bdquo;designated community&rdquo; nach der OAIS-Terminologie) gedacht wird, fehlt es vor allem bei einzelnen Messkampagnen oder bei kleineren, institutionell angelegten, kontinuierlich arbeitenden Messnetzen an einer definierten Beschreibung des Entstehungsprozesses der Daten. Eine m&ouml;glichst umfassende inhaltliche Anreicherung eines Datensatzes, wie h&auml;ufig in &uuml;berregional organisierten Datennetzen vorhanden, erleichtert auch fachfremden Nutzern oder Einsteigern im Forschungsgebiet die Interpretation von Ergebnissen und f&ouml;rdert damit nicht zuletzt den interdisziplin&auml;ren Austausch.</p>
	<p>In vielen F&auml;llen werden Daten auf Seiten der Datenproduzenten einfach nur gesammelt. Messausf&auml;lle, -fehler, -inkonsistenzen werden, wenn &uuml;berhaupt, erst nachtr&auml;glich in den Daten dokumentiert. Je nach Aufgabenbereich der erfassenden Institution (Lehre, Forschung, &Uuml;berwachung, Berichtspflicht) und Personalausstattung wird der Qualit&auml;tspr&uuml;fung ein unterschiedlich hoher Grad an Wichtigkeit beigemessen. In einigen F&auml;llen werden hierf&uuml;r Programme genutzt, die von Ingenieurb&uuml;ros im Auftrag entwickelt wurden. Eine Langzeitarchivierung ohne inhaltliche Qualit&auml;tssicherung wird von den meisten Institutionen als nicht sinnvoll, wenn nicht sogar als &uuml;berfl&uuml;ssig angesehen.</p>

	<a name="2" id="2"></a><h3>Exemplarische &Uuml;bergabeworkflows</h3>
	<p>Was ist nun die Erkenntnis aus den M&auml;ngeln? Wie steht es um das Wie des Einlagerns von Forschungsdaten? Im Folgenden wird beispielhaft das erste Konzept von &Uuml;bergabe-Workflows im Rahmen von EWIG dargestellt &ndash; f&uuml;r den geduldigen Leser wird au&szlig;erdem die Thunfisch-Allegorie aus dem Titel aufgel&ouml;st.</p>
	<p>Es ist schwer bis unm&ouml;glich, Wissenschaftlern Vorschriften zu machen, insbesondere wenn als Nebeneffekt aus ihrer Sicht nur wenig Nutzen aus den Vorschriften zu ziehen ist. [<a name="fn23b"></a><a href="#fn23">Fn 23</a>] Stattdessen sollte ein Angebot gemacht werden, das Wissenschaftler nicht ablehnen k&ouml;nnen. In Anlehnung an ein Zitat von Jens Klump vom GFZ Potsdam l&auml;sst sich das Problem mit einem weiterem Bild beschreiben: &bdquo;Dealing with Policies for Research Data is like herding cats over the prairie.&rdquo; Um beim Bild der Katzen zu bleiben, nehme man ein Thunfischsandwich oder klappere mit dem Dosen&ouml;ffner. Momentan zur Verf&uuml;gung stehende Werkzeuge, Workflows und Policies gehen aber, wie oben angedeutet, bestenfalls als Trockenfutter durch. Solange es keine wirksamen Incentives f&uuml;r Datenpublikation gibt, lassen sich Wissenschaftler nur schwer locken. [<a name="fn24b"></a><a href="#fn24">Fn 24</a>]</p>
	<p>Aus Sicht eines Langzeitarchivs oder auch Forschungsdatenrepositoriums als Dienstleister sollte die Aufgabe in diesem Sinn lauten, den Prozess der Daten&uuml;bergabe f&uuml;r Wissenschaftler schmackhafter zu machen. Pragmatisches Ziel des Dienstleisters ist es, ein valides Submission Information Package (&bdquo;SIP&rdquo; nach OAIS-Terminologie) zu erhalten. Die beiden geowissenschaftlichen Partner im EWIG-Projekt liefern Testdaten f&uuml;r die beispielhafte Umsetzung eines &Uuml;bergabeworkflows. W&auml;hrend im Institut f&uuml;r Meteorologie der FU Berlin SIPs direkt aus einem Dateisystem generiert werden, setzt das GeoForschungsZentrum Potsdam (GFZ) ein auf Fedora Commons basierendes Repositorium ein, das gleichsam eine zus&auml;tzliche Serviceschicht (Pre-Ingest) realisiert. Die beiden exemplarischen Anwendungsf&auml;lle decken einen typischen Bedarf in der (geo-)wissenschaftlichen Community ab und sollten sich aller Voraussicht nach ohne gr&ouml;&szlig;ere Probleme generalisieren lassen &ndash; soweit ist es aber noch nicht.</p>
	<p>Einige der zu archivierenden Pakete beinhalten neben tabellarischen Messwerten in Form von comma-separated-values (.csv) auch erl&auml;uternde Grafiken (PDF) oder dokumentierende Bilder (JPEG). Im Ingest-Modul des aktuell evaluierten Archiv-Frameworks Archivematica [<a name="fn25b"></a><a href="#fn25">Fn 25</a>] k&ouml;nnen standardisiert alle g&auml;ngigen Formatvalidierer eingesetzt werden, was in der automatisierten Anreicherung der SIPs mit technischen Metadaten von Vorteil ist. Zudem lassen sich zus&auml;tzliche Tools zur technischen Qualit&auml;tssicherung einbinden. Die technische Pr&uuml;fung im Verlauf des Ingest bietet die Entscheidungsgrundlage &uuml;ber eine eventuell notwendige Normalisierung (Migration) der Daten oder R&uuml;ckfragen an den Datenproduzenten. Sofern die Datenproduzenten &uuml;ber entsprechendes Know-How verf&uuml;gen, kann die technische Qualit&auml;tssicherung vom Dienstleister an den Produzenten vorverlagert werden (Pre- oder auch Pre-Pre-Ingest).</p>
	<p>Gro&szlig;es Augenmerk wird der Erstellung der Metadata Encoding &amp; Transmission Standard (METS)-Datei des SIPs gewidmet. METS ist der defacto-Standard f&uuml;r die Kapselung aller Metadaten (inhaltlich, administrativ, technisch), die das eigentliche Forschungsdatum (Dateiobjekt) beschreiben. Die METS-XML-Datei soll m&ouml;glichst kontextlos eine Interpretation des Informationspakets erm&ouml;glichen (im Zweifel k&ouml;nnen auch Menschen den Text vollst&auml;ndig lesen). [<a name="fn26b"></a><a href="#fn26">Fn 26</a>] In beschreibenden Dateien zu den geowissenschaftlichen Forschungsdaten sind zum Teil &auml;u&szlig;erst informative Metadaten enthalten, die bei einer eingeschr&auml;nkten Metadatenerfassung etwa mittels Dublin Core nicht ber&uuml;cksichtigt w&uuml;rden, die aber unbedingt Eingang in die METS-Datei des SIPs finden sollten. Ein geeignetes Mapping l&auml;sst sich &uuml;ber ein Tool im Ingest-Prozess von Archivematica realisieren, an dem zurzeit gearbeitet wird. Neben dem Mapping ausgew&auml;hlter Teile werden auch alle vorhandenen Metadaten (zum Beispiel DIF [<a name="fn27b"></a><a href="#fn27">Fn 27</a>]) &uuml;ber das &lt;mdwrap&gt; Element der METS -Datei sozusagen im Original mit eingebunden und bieten damit sehr umfangreiche Recherchem&ouml;glichkeiten auch in den inhaltlichen Metadaten. Ziel im Workflow ist es, die METS-Datei und damit die Metadaten &uuml;ber den Solr-Index des Archivematica-Frameworks durchsuchbar zu machen. Hierzu bedarf es einer &Uuml;bereinkunft zwischen dem Datenlieferanten und dem Archiv dar&uuml;ber, welche der Metadaten an welcher Stelle der METS-Metadaten integriert werden sollen. Diese &Uuml;bereinkunft ist Teil der &Uuml;bergabevereinbarung (&bdquo;submission agreement&rdquo; nach OAIS-Terminologie). Kommerzielle Anbieter von Archivierungsprozessen veranschlagen f&uuml;r diesen Prozess mit der Definition der verschiedene Rollen und Aufgaben, der Storage Infrastruktur, der Access-Komponente, sowie des Ingest-Workflows durchaus einen Zeitraum von bis zu einem Jahr. Auf vertraglicher Basis dieser Vereinbarung werden die jeweiligen SIPs generiert und im Ingest des Archivs gegen die Vereinbarung validiert. F&uuml;r die Erstellung der Forschungsdatenpakete in Form von SIPs werden bei den EWIG-Projektpartnern noch verschiedene Varianten getestet. Hier muss entschieden werden, ob ein SIP erst beim Dienstleister (in diesem Fall dem Zuse-Institut) auf Grundlage der gelieferten Daten und Metadaten erzeugt wird oder bereits bei den Datenproduzenten. Da sowohl am Institut f&uuml;r Meteorologie als auch am GFZ Know-How zur Erzeugung von METS-Dateien vorhanden ist, bietet es sich in diesem Fall an, den Pre-Ingest mit der SIP-Erzeugung durch die Datenproduzenten durchf&uuml;hren zu lassen. Im Zuse-Institut (ZIB) erfolgt dann die technische Qualit&auml;tssicherung der SIPs mit Hilfe der in Archivematica eingebundenen Werkzeuge. [<a name="fn28b"></a><a href="#fn28">Fn 28</a>] Archivematica setzt ebenfall METS, sowie PREMIS [<a name="fn29b"></a><a href="#fn29">Fn 29</a>] und BagIt [<a name="fn30b"></a><a href="#fn30">Fn 30</a>] zur anschlie&szlig;enden Erzeugung von Archivinformationspaketen (AIP) ein, die im Archival Storage gelagert werden k&ouml;nnen (in diesem Fall das hierarchische Speichermanagement im ZIB). Da EWIG lediglich testweise Daten &uuml;bernimmt, werden keine vertraglichen &Uuml;bergabevereinbarungen mit den Projektpartnern geschlossen. Grunds&auml;tzlich d&uuml;rften f&uuml;r Dienstleister, die disziplin&uuml;bergreifend generische Services anbieten wollen, pragmatische Beschr&auml;nkungen bei der Detailliertheit dieser Vereinbarung sinnvoll sein.</p>

	<a name="3" id="3"></a><h3>Fachspezifische Lehrmodule</h3>
	<p>EWIG bearbeitet in einer dritten Komponente die Entwicklung von fachspezifischen Lehrmodulen und damit einen weiteren Aspekt der Frage &bdquo;was tun?&rdquo;. Jeder Wissenschaftler ist an gut dokumentierten und frei verf&uuml;gbaren Datens&auml;tzen interessiert. Wenn es darum geht, die eigenen Daten gut zu dokumentieren und auffindbar zu machen, beginnen die Probleme. Gegen die &bdquo;Ur&auml;ngste&rdquo; der Forscher in Bezug auf die Publikation ihrer Daten [<a name="fn31b"></a><a href="#fn31">Fn 31</a>], wird nur ein genereller Wandel in den Umgangsformen mit Daten innerhalb der verschiedenen Communities wirken k&ouml;nnen. Um dies zu erreichen, ist eine Sensibilisierung f&uuml;r die Bedeutung eines sorgf&auml;ltigen Umgangs mit eigenen Forschungsdaten und m&ouml;glichst die Vermittlung von Anwendungswissen bereits in der Ausbildung ein wichtiger Baustein.</p>
	<p>Am Institut f&uuml;r Meteorologie der Freien Universit&auml;t Berlin wird im Rahmen von EWIG seit dem WS 2012/2013 das Modul &bdquo;Datenmanagement&rdquo; in der Bachelor-Ausbildung im Fach Meteorologie angeboten, das auch die langfristige Verf&uuml;gbarkeit von Forschungsdaten thematisiert. Teil des als Konzept in EWIG geplanten Curriculums wird sein, angehenden Wissenschaftlern &bdquo;eingelagerte&rdquo; Datens&auml;tze ihrer Vorsemester aus dem Langzeitarchiv zur Bearbeitung zu &uuml;bergeben. K&ouml;nnen sie damit etwas anfangen? Sind die Daten interpretierbar? Wenn nein, warum nicht und was k&ouml;nnte man besser machen? Denkbar ist zuk&uuml;nftig auch ein Austausch und die Nutzung von Daten &uuml;ber Fachgrenzen hinweg, wobei es auch sinnvoll w&auml;re, beispielsweise eine Gruppe von Geowissenschaftlern mit sozialwissenschaftlichen Daten arbeiten zu lassen und umgekehrt. So k&ouml;nnte eine &bdquo;arch&auml;ologische&rdquo; Sichtweise entstehen, die hilft, das Problembewusstsein zu sch&auml;rfen. Die Studierenden agieren gleichsam als fiktive Arch&auml;ologen &ndash; um den Inhalt ihres gefundenen &bdquo;Datenschatzes&rdquo; heben zu k&ouml;nnen, m&uuml;ssen sie nicht nur das Objekt (die Datei) selber lesen k&ouml;nnen, sondern auch die beschreibenden Informationen interpretieren. K&ouml;nnen die heute erzeugten Informationspakete eines Langzeitarchivs diesen Kontext verl&auml;sslich bewahren?</p>

	<hr/>
    <h3>Literaturverzeichnis</h3>
	<p>DFG &ndash; Deutsche Forschungsgemeinschaft (2010). Aufforderung zur Antragstellung &ndash; Informationsmanagement &ndash; Ausschreibung &bdquo;Informationsinfrastrukturen f&uuml;r Forschungsdaten&rdquo; (28.04.2010). <a href="http://www.dfg.de/download/pdf/foerderung/programme/lis/ausschreibung_forschungsdaten_1001.pdf">http://www.dfg.de/download/pdf/foerderung/programme/lis/ausschreibung_forschungsdaten_1001.pdf</a></p>
	<p>DFG &ndash; Deutsche Forschungsgemeinschaft (2012). Leitfaden f&uuml;r die Antragstellung &ndash; Projektantr&auml;ge. DFG-Vordruck 54.01 &ndash; 04/13. <a href="http://www.dfg.de/formulare/54_01/54_01_de.pdf">http://www.dfg.de/formulare/54_01/54_01_de.pdf</a></p>
	<p>DFG &ndash; Deutsche Forschungsgemeinschaft (2013). Erg&auml;nzung der Empfehlungen der Deutschen Forschungsgemeinschaft zur Sicherung guter wissenschaftlicher Praxis &ndash; Juli 2013. <a href="http://www.dfg.de/download/pdf/dfg_im_profil/reden_stellungnahmen/download/empfehlung_wiss_praxis_0198_ergaenzungen.pdf">http://www.dfg.de/download/pdf/dfg_im_profil/reden_stellungnahmen/download/empfehlung_wiss_praxis_0198_ergaenzungen.pdf</a></p>
	<p>Kindling, M. (2013). Qualit&auml;tssicherung im Umgang mit digitalen Forschungsdaten. Information &ndash; Wissenschaft &amp; Praxis, 64 (2-3), 69-172. <a href="http://dx.doi.org/10.1515/iwp-2013-0020" target="_blank">doi:10.1515/iwp-2013-0020</a></p>
	<p>Klump, J. (2010). Digitale Forschungsdaten. In: Neuroth, H., O&szlig;wald, A., Scheffel, R., Strathmann &amp; M. Jehn. nestor Handbuch: Eine kleine Enzyklop&auml;die der digitalen Langzeitarchivierung [Version 2.3]. S. 104-105. <a href="http://nestor.sub.uni-goettingen.de/handbuch/nestor-handbuch_23.pdf">http://nestor.sub.uni-goettingen.de/handbuch/nestor-handbuch_23.pdf</a></p>
	<p>Marchionini, G., Lee, C. A., Bowden, H., &amp; M. Lesk (2012). Curating for Quality: Ensuring Data Quality to Enable New Science: Final report of Invitational Workshop sponsored by the National Science Foundation, Sept. 10-11, 2012. <a href="http://datacuration.web.unc.edu/files/2012/10/NSF_Data_Curation_Workshop_Report.pdf">http://datacuration.web.unc.edu/files/2012/10/NSF_Data_Curation_Workshop_Report.pdf</a></p>
	<p>Osswald, A., &amp; Strathmann, S. (2012). The Role of Libraries in Curation and Preservation of Research Data in Germany: Findings of a survey. In: 78th IFLA General Conference and Assembly. <a href="http://conference.ifla.org/sites/default/files/files/papers/wlic2012/116-osswald-en.pdf">http://conference.ifla.org/sites/default/files/files/papers/wlic2012/116-osswald-en.pdf</a></p>
	<p>Pampel, H., &amp; Bertelmann, R. (2011). &#8220;Data Policies&#8221; im Spannungsfeld zwischen Empfehlung und Verpflichtung. In B&uuml;ttner, S., Hobohm, H.-C. &amp; L. M&uuml;ller  (Hrsg.). Handbuch Forschungs­datenmanagement. Bad Honnef: Bock + Herchen. S. 49-61. <a href="urn:nbn:de:kobv:525-opus-2287" target="_blank">urn:nbn:de:kobv:525-opus-2287</a></p>
	<p>Reilly, S. (2012). From cataloguing to digital curation: the role of libraries in data exchange. Proceedings of the 9th International Conference on Preservation of Digital Objects. 1.-5.10. 2012. Toronto. <a href="http://depot.knaw.nl/13004/1/iPress2012Horik_Interoperability_Framework_for_Persistent_Identifiers.pdf">http://depot.knaw.nl/13004/1/iPress2012Horik_Interoperability_Framework_for_Persistent_Identifiers.pdf</a></p>
	<p>Tenopir, C., Allard, S., Douglass, K., Aydinoglu, A. U., Wu, L. &amp; E. Read (2011) Data Sharing by Scientists: Practices and Perceptions. PLoS ONE 6(6). <a href="http://dx.doi.org/10.1371/journal.pone.0021101" target="_blank">doi:10.1371/journal.pone.0021101</a></p>
	<p>The Royal Society (2012). Science as an open enterprise. The Royal Society Science Policy Centre report 02/12. London: Royal Society. <a href="http://royalsociety.org/uploadedFiles/Royal_Society_Content/policy/projects/sape/2012-06-20-Science-Open-EnterpriseEPUBMOBI.zip">http://royalsociety.org/uploadedFiles/Royal_Society_Content/policy/projects/sape/2012-06-20-Science-Open-EnterpriseEPUBMOBI.zip</a></p>
	<p>Treloar, A., Groenewegen, D. &amp; C. Harboe-Ree (2007). The Data Curation Continuum. Managing Data Objects in Institutional Repositories. D-Lib Magazine, 13, 9/10. <a href="http://dx.doi.org/10.1045/september2007-treloar" target="_blank">doi:10.1045/september2007-treloar</a></p>
	<p>Winkler-Nees, S. (2011). Anforderungen an wissenschaftliche Informationsinfrastrukturen. Working Paper Series des Rates f&uuml;r Sozial- und Wirtschaftsdaten, 180. Berlin. <a href="http://hdl.handle.net/10419/75325" target="_blank">http://hdl.handle.net/10419/75325</a></p>
	<p>Winkler-Nees, S. (2012). Stand der Diskussion. National. In: Neuroth, H. Strathmann, S., O&szlig;wald, A., Scheffel, R., Klump, J. &amp; J. Ludwig (Hrsg.). Langzeitarchivierung von Forschungsdaten: Eine Bestandsaufnahme. <a href="http://nbn-resolving.de/urn:nbn:de:0008-2012031401" target="_blank">http://nbn-resolving.de/urn:nbn:de:0008-2012031401</a></p>
	
	<hr/>
	<h3>Fu&szlig;noten</h3>
	<p class="fussnote">
	<a name="fn01"></a>
	 [01] EWIG ist ein Projekt des KOBV am Zuse-Institut Berlin mit den Partnern Helmholtz-Zentrum Deutsches GeoForschungsZentrum Potsdam und Institut f&uuml;r Meteorologie der Freien Universit&auml;t Berlin. Aufgabe ist die &bdquo;Entwicklung von Workflowkomponenten f&uuml;r die Langzeitarchivierung von Forschungsdaten in den Geowissenschaften&rdquo;. Vgl. http://ewig.gfz-potsdam.de/. Drei Kernziele werden in der zweiten Projektphase bis August 2014 verfolgt: 1. Entwicklung von Policies, 2. Aufbau von Workflows mit Fokus auf technischer Qualit&auml;tssicherung, 3. Entwicklung von Lehr- und Weiterbildungsmodulen f&uuml;r Studierende und Fachwissenschaftler. [<a href="#fn01b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn02"></a>
	 [02] <a href="http://www.dkrz.de/daten/wdcc" target="_blank">http://www.dkrz.de/daten/wdcc</a> [<a href="#fn02b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn03"></a>
	 [03] <a href="http://www.wdc-mare.org/" target="_blank">http://www.wdc-mare.org/</a> [<a href="#fn03b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn04"></a>
	 [04] Eine &Uuml;bersicht und Typisierung von Forschungsdaten-Repositorien wird im Projekt re3data.org erstellt: <a href="http://www.re3data.org/" target="_blank">http://www.re3data.org/</a>. [<a href="#fn04b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn05"></a>
	 [05] Der Begriff &bdquo;Daten&rdquo; bezieht sich in dieser Arbeit auf &bdquo;Forschungsdaten&rdquo; und wird hier aus praktischen Gr&uuml;nden synonym verwendet. Forschungsdaten werden in verschiedenen Fachkontexten unterschiedlich definiert, aus Sicht der Autoren sind Forschungsdaten jedenfall nicht darauf beschr&auml;nkt, lediglich Grundlage f&uuml;r eine wissenschaftliche Textpublikation zu sein. Eine weitergefasste, treffendere Definition ist einer DFG-Ausschreibung von 2010 zu entnehmen: &bdquo;Unter Forschungsdaten sind im Sinne dieser F&ouml;rderma&szlig;nahme digitale und elektronisch speicherbare Daten zu verstehen, die im Zuge eines wissenschaftlichen Vorhabens z.B. durch Quellenforschungen, Experimente, Messungen, Erhebungen oder Befragungen entstehen.&rdquo; (DFG 2010). [<a href="#fn05b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn06"></a>
	 [06] In diesem Beitrag wird keine strikte definitorische Abgrenzung zwischen digitalem Langzeitarchiv und Repositorium als Zielsystem f&uuml;r Forschungsdaten beachtet. Aus Sicht der Autoren ist es aus der Perspektive der abliefernden Datenproduzenten nicht zwingend notwendig (wenn auch w&uuml;nschenswert) bei der Datenvorbereitung die &bdquo;dauerhafte Dom&auml;ne&rdquo; mitzudenken. [<a href="#fn06b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn07"></a>
	 [07] In der Erg&auml;nzung zu den Empfehlungen der DFG von Juli 2013 ist weiterhin von Prim&auml;rdaten die Rede, die in der Institution zehn Jahre vorgehalten werden m&uuml;ssen. Es gibt keine Empfehlung zur &Uuml;bergabe an Forschungsdatenrepositorien oder Langzeitarchive. Immerhin wird erstmals die Nutzung von Prim&auml;rdaten erw&auml;hnt, allerdings ohne Empfehlung des freien Zugangs im Sinn von Open Access (DFG 2013). [<a href="#fn07b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn08"></a>
	 [08] Auch die DFG fordert inzwischen Stellungnahmen in Projektantr&auml;gen zum Umgang mit Forschungsdaten. Vgl. DFG (2012), S. 6: &bdquo;Wenn aus Projektmitteln systematisch (Mess-)Daten erhoben werden, die f&uuml;r die Nachnutzung geeignet sind, legen Sie bitte dar, welche Ma&szlig;nahmen ergriffen wurden bzw. w&auml;hrend der Laufzeit des Projektes getroffen werden, um die Daten nachhaltig zu sichern und ggf. f&uuml;r eine erneute Nutzung bereit zu stellen. Bitte ber&uuml;cksichtigen Sie dabei auch - sofern vorhanden - die in Ihrer Fachdisziplin existierenden Standards und die Angebote bestehender Datenrepositorien.&rdquo; [<a href="#fn08b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn09"></a>
	 [09] Die dauerhafte Dom&auml;ne als Ort der langfristigen Sicherung von Forschungsdaten erg&auml;nzt das Dom&auml;nenkonzept des Digital Curation Continuum nach Treloar et al. (2007), s. Klump (2010). [<a href="#fn09b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn10"></a>
	 [10] Der Begriff Langzeitverf&uuml;gbarkeit wird zunehmend anstelle des Begriffs Langzeitarchivierung verwendet, da er inhaltlich treffender ist. Langzeitarchivierung ist aus Sicht der Autoren allerdings etabliert und auch f&uuml;r Externe nachvollziehbarer. In diesem Text werden beide Begriffe verwendet. [<a href="#fn10b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn11"></a>
	 [11] Ausf&uuml;hrliche Diskussionen zum Stand und der Weiterentwicklung der technischen Qualit&auml;tssicherung wurden beim &bdquo;Curating for Quality&rdquo; Workshop der National Science Foundation im September 2012 gef&uuml;hrt. Die Ergebnisse mit Empfehlungen sind im Final Report zusammengestellt (Marchionini et al. 2012). [<a href="#fn11b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn12"></a>
	 [12] Jedenfalls dann, wenn als Erfolgskriterien die Nachvollziehbarkeit und Nachnutzung der Forschungsdaten angenommen werden k&ouml;nnen. Zu Fragen des Qualit&auml;tsmanagements mit Schwerpunkt auf organisatorischen Fragen vgl. Kindling (2013). [<a href="#fn12b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn13"></a>
	 [13] Expertengespr&auml;che wurden nicht explizit in Form von Interviews im Sinn der qualitativen Sozialforschung durchgef&uuml;hrt. Die Auswahl wurde subjektiv nach Einsch&auml;tzung des beim Gespr&auml;chspartner vermuteten Stands der Technik beziehungsweise nach Repr&auml;sentativit&auml;t f&uuml;r ein Fachgebiet gef&uuml;hrt. Neben Gespr&auml;chen mit der Bayerischen Staatsbibliothek und dem Deutschen Klimarechenzentrum wurden beispielsweise das Deutsche Arch&auml;ologische Institut und das Leibniz-Institut f&uuml;r Astrophysik Potsdam befragt. [<a href="#fn13b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn14"></a>
	 [14] Der Hintergrund f&uuml;r das Fehlen von Policies scheint weniger inhaltlich-technischer sondern eher organisatorisch-pragmatischer Natur zu sein. In Deutschland sind Policies zum Forschungsdatenmanagement selbst als &bdquo;schwache&rdquo; Eigenverpflichtung von Einrichtungen wie Universit&auml;ten offenbar nur schwer institutionsweit durchzusetzen. [<a href="#fn14b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn15"></a>
	 [15] Beim WDC-Mare (Pangaea) sind beispielsweise f&uuml;r das inhaltliche &bdquo;Editorial Review&rdquo; aller eingereichten Daten rund ein Dutzend Wissenschaftler als hauptamtliche Datenkuratoren besch&auml;ftigt. [<a href="#fn15b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn16"></a>
	 [16] Vgl. Winkler-Nees (2011): &bdquo;Vermittlung von Grundverst&auml;ndnis f&uuml;r Informationsmanagement ist bereits in der Ausbildung wichtig und bisher kaum verf&uuml;gbar. Hier besteht Potenzial seitens der Informationsinfrastruktureinrichtungen sich aktiv zu beteiligen.&rdquo; Siehe auch Pampel & Bertelmann (2011): &bdquo;Es fehlt in vielen Disziplinen an Kulturen des zeitgem&auml;&szlig;en Umgangs mit wissenschaftlichen Daten und damit auch an einer Professionalisierung der entsprechenden Angebote. So m&uuml;ssen z.B. auch Nachwuchswissenschaftler im Rahmen der Ausbildung mit geeigneten Ma&szlig;nahmen des Forschungsdatenmanagements vertraut gemacht werden.&rdquo; In Deutschland sehen sich zunehmend Hochschulbibliotheken in der Rolle der Anbieter und Kompetenzvermittler f&uuml;r Wissenschaftler. [<a href="#fn16b" class="back">zur&uuml;ck</a>]
	</p><p class="fussnote">
	<a name="fn17"></a>
	 [17] <a href="http://www.library.ethz.ch/Ueber-uns/Projekte/Digitaler-Datenerhalt" target="_blank">http://www.library.ethz.ch/Ueber-uns/Projekte/Digitaler-Datenerhalt</a> [<a href="#fn17b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn18"></a>
	 [18] <a href="http://www.szf.tu-berlin.de/" target="_blank">http://www.szf.tu-berlin.de/</a> [<a href="#fn18b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn19"></a>
	 [19] Vgl. Osswald &amp; Strathmann (2012), Reilly (2012) [<a href="#fn19b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn20"></a>
	 [20] Wir befinden uns mit den Werkzeugen, die momentan im Ingest-Workflow zur Verf&uuml;gung stehen, auf einer &auml;hnlichen Stufe wie Automobile um 1910. Zweifellos war eine Fortbewegung m&ouml;glich, allerdings nur f&uuml;r Experten (ehrf&uuml;rchtig Automobilisten genannt), die mit den Vorg&auml;ngen in ihrem Antriebssystem vertraut waren. [<a href="#fn20b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn21"></a>
	 [21] Paul Wheatley hat die Idee in einem Positionspapier f&uuml;r den Aligning Digital Preservation across Nations Workshop im Januar 2013 in Amsterdam dargestellt: <a href="http://digitalcurationexchange.org/system/files/wheatley-tools-registry_0.pdf">http://digitalcurationexchange.org/system/files/wheatley-tools-registry_0.pdf</a>. [<a href="#fn21b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn22"></a>
	 [22] Ein aktueller Ansatz ist das &bdquo;preservation watch system&rdquo; Scout, das derzeit im Rahmen des SCAPE-Projekts der EU (7. Framework Programme) aufgebaut wird: <a href="http://scout.scape.keep.pt/" target="_blank">http://scout.scape.keep.pt/</a>. [<a href="#fn22b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn23"></a>
	 [23] Diese Einsch&auml;tzung ist allerdings stark von der jeweiligen Fachkultur abh&auml;ngig. [<a href="#fn23b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn24"></a>
	 [24] Siehe Tenopir et al. (2011) f&uuml;r eine Zusammenstellung der Gr&uuml;nde, weshalb Wissenschaftler zur&uuml;ckhaltend sind bei der Weitergabe ihrer Daten. Siehe auch The Royal Society (2012). [<a href="#fn24b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn25"></a>
	 [25] <a href="http://www.archivematica.org" target="_blank">http://www.archivematica.org</a> [<a href="#fn25b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn26"></a>
	 [26] METS wird von der Library of Congress verwaltet. Online wird auch eine Reihe von Werkzeugen zur Erzeugung von METS vorgestellt: <a href="http://www.loc.gov/standards/mets/mets-tools.html" target="_blank">http://www.loc.gov/standards/mets/mets-tools.html</a>. [<a href="#fn26b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn27"></a>
	 [27] DIF steht f&uuml;r Data Interchange Format, ein Dateiformat, das h&auml;ufig f&uuml;r tabellarische Messwerte verwendet wird. <a href="http://en.wikipedia.org/wiki/Data_Interchange_Format" target="_blank">http://en.wikipedia.org/wiki/Data_Interchange_Format</a>. [<a href="#fn27b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn28"></a>
	 [28] Standardm&auml;&szlig;ig zum Beispiel Dateiidentifizierung und -validierung mit dem Toolwrapper FITS (File Information Tool Set): <a href="http://code.google.com/p/fits/" target="_blank">http://code.google.com/p/fits/</a>. [<a href="#fn28b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn29"></a>
	 [29] <a href="http://en.wikipedia.org/wiki/Preservation_Metadata:_Implementation_Strategies_(PREMIS)" target="_blank">http://en.wikipedia.org/wiki/Preservation_Metadata:_Implementation_Strategies_(PREMIS)</a> [<a href="#fn29b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn30"></a>
	 [30] <a href="http://en.wikipedia.org/wiki/BagIt" target="_blank">http://en.wikipedia.org/wiki/BagIt</a> [<a href="#fn30b" class="back">zur&uuml;ck</a>]
	</p>
	<p class="fussnote">
	<a name="fn31"></a>
	 [31] Vgl. zum Beispiel Winkler-Nees (2012). In den Expertengespr&auml;chen in EWIG wurden seitens der Wissenschaftler keine diesbez&uuml;glichen Bedenken zur Datenpublikation ge&auml;u&szlig;ert &ndash; ganz im Gegenteil. Dies d&uuml;rfte allerdings an der Auswahl der Gespr&auml;chspartner gelegen haben, da nur Institutionen mit Erfahrung und Engagement im Forschungsdatenmanagement besucht wurden. [<a href="#fn31b" class="back">zur&uuml;ck</a>]
	</p>

	<hr/>
	<p><strong>Tim Hasler</strong> ist wissenschaftlicher Mitarbeiter in der Verbundzentrale des KOBV am Zuse-Institut Berlin. Er arbeitet im Projekt EWIG an Workflows f&uuml;r die Forschungsdaten&uuml;bernahme in Langzeitarchive. Dabei nutzt das Projekt die enge Kooperation mit der Servicestelle Digitalisierung am Zuse-Institut, die an einer L&ouml;sung zur &Uuml;bernahme digitaler Kulturobjekte arbeitet.</p>
	<p><strong>Wolfgang Peters-Kottig</strong> ist wissenschaftlicher Mitarbeiter in der Verbundzentrale des KOBV am Zuse-Institut Berlin. Er arbeitet im Projekt EWIG an Workflows f&uuml;r die Forschungsdaten&uuml;bernahme in Langzeitarchive. Dabei nutzt das Projekt die enge Kooperation mit der Servicestelle Digitalisierung am Zuse-Institut, die an einer L&ouml;sung zur &Uuml;bernahme digitaler Kulturobjekte arbeitet.</p>
</div>

    

</article>




        <footer class="footer">
<hr>
<p><a href="https://creativecommons.org/licenses/by/4.0/">All content licensed under Creative Commons Attribution 4.0 International (CC BY 4.0)</a>, if not otherwise stated.
</p>
<p>LIBREAS. Library Ideas wird herausgegeben am <a href="https://www.ibi.hu-berlin.de/">Institut für Bibliotheks- und Informationswissenschaft</a> der <a href="https://www.hu-berlin.de/">Humboldt-Universität zu Berlin</a></p>
<p>Hosted on <a href="http://github.com/libreas/libreas.github.io">GitHub</a>, made with <a href="http://octopress.org/">Jekyll/Octopress</a> and <a href="http://johnmacfarlane.net/pandoc/">pandoc</a></p>

<p>ISSN: 1860-7950</p>


    LIBREAS. Library Ideas

(last updated: <a href="https://github.com/libreas/libreas.github.io/commits/master">2022-06-06</a>)</p>

</footer>
      </div>
    </div>
<label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>
  </body>
</html>
